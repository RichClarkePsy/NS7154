[{"path":"index.html","id":"welcome","chapter":"1 Welcome","heading":"1 Welcome","text":"Welcome R Handbook NS7514 Health Context: Cell SocietyOver course semester book guide use R RStudio organise, visualise, analyse health data related lecture content week module. book take absolute basics R, point able make stunning visualisations, expert analysis , importantly, conduct analysis assignment.Week 1 - Introduction module / Introduction RWeek 2 - Global burden disease / Basic data visualisationWeek 3 - Genetics & epigenetics / Working data filesWeek 4 - Biological systems involved health / Working categorical dataWeek 5 - Psychobio interaction / Simple linear regressionWeek 6 - Lab based biometric data collection methods / Catch weekWeek 7 - public health? / Multiple regressionWeek 8 - Applied public health / Logistic regressionWeek 9 - Social determinants health / Assignment data overviewWeek 10 - Planetary health / Introduction RMarkdownWeek 11 & 12 - Biopsychosocial connections / Working analysis","code":""},{"path":"week-1---why-learn-r.html","id":"week-1---why-learn-r","chapter":"2 Week 1 - Why learn R?","heading":"2 Week 1 - Why learn R?","text":"completed undergraduate psychology degree good chance taught statistical analysis using SPSS STATA. programs great, capable conducting amazing analysis, data real world often lot messier data saw undergraduate degree. want leave MSc skills needed deal messiness, wherever may end , R excellent place hone skills.Need convincing? usual go-reasons learning R psychology student.1. R open access therefore freeSPSS STATA ludicrously expensive. personal licence, last check, cost little $1000 per year. fine university cover (now), move away academia perhaps charity non-governmental organisation cost many willing pay ., may find many jobs perfectly capable , knowledge point view, just access tools trained .position finished last post-doc. Doors closed - really interesting doors done lot good - due skill base narrow applicable . want case . end course able analysis can already paid software, free accessible language quickly becoming highly desirable skill graduate .2. Data wranglingSay want conduct longitudinal research. find participants, send surveys month, also perhaps visit person take bio-physiological measurements (blood pressure, BMI etc). data recorded saved across multiple different excel files. participants drop fail respond time points. match participants final dataset combine files format able run analysis?problem rarely cover undergraduate, common essential part research process, especially health data collected third party (.e. charity NHS). days learnt R kind problem led copy pasting chunks data excel, entering data SPSS hand, number long laborious processes prone silly mistakes lapses concentration poor work processes.skill cope data problem described , many others, known data wrangling skill best deployed code. end module, able raw data project together folder, open script written, click run end perfect dataset ready analysis every time.3. Data visulisationsI never truly understand data can see . Relationships variables, differences groups, location data, can visulised quickly effectively using R. favourites creating across course semester:great thing creating code next time come across similar data format can simply copy previous code adapt needs. clicking around excel trying find colours arrangement last time, ugly SPSS outputs, just publication ready figures communicate amazing findings way words just capture.4. ReproducabilityIf psychology may heard \"Replication Crisis\". Findings previously held reliable understandings human condition crumbling dust apply rigour scientific method., now infamous, 2015 study Open Science Collaboration followed methodology 100 experimental reports, single year (2008), published range high-ranking journals. aim see many findings replicated (.e. repeated, produced results). 100 39 found successful replicate.finding proved watershed moment psychology whereby many us starting question reliability foundational work.One solution, suggested academic community, make process science far transparent. R comes . use R means solves issues replication crisis, submitting code along making data open access, readers work longer need \"take word \" conducted appropriate analysis correctly reported results. can now check .Journals also starting take note culture shift starting require submission analysis scripts. , luck, skill start align getting published future.Hopefully convinced importance learning R psychology student. link particularly good talk Phil McAleer University Glasgow moved undergraduate degree towards focus reproducible research, using R statistics.Now learning!","code":""},{"path":"week-1---getting-started.html","id":"week-1---getting-started","chapter":"3 Week 1 - Getting started","heading":"3 Week 1 - Getting started","text":"","code":""},{"path":"week-1---getting-started.html","id":"installing-r-and-rstudio","chapter":"3 Week 1 - Getting started","heading":"3.1 Installing R and RStudio","text":"R programming language ’ll learning write code , RStudio known Integrated Development Environment (IDE) makes working R easier. largely use terms \"R\" \"RStudio\" interchangeably throughout course, can think writing R writing English RStudio program write . write written assignment NotePad Microsoft Word gives lot freedom ’s often default. logic true R, using RStudio just makes life lot easier.\nget started first need install language R IDE RStudio. can installed, free, company maintains , Posit. need select operating system (Windows Mac).One best things using R RStudio widely used across many academic disciplines, professional world. many guides installation. hit issue installation, likely others . helpful links help install R RStudio home computer (highly recommend ):University Glasgow PsyTeachR installation guideYouTube video showing download process WindowsYouTube video showing download process Mac","code":""},{"path":"week-1---getting-started.html","id":"opening-rstudio-for-the-first-time","chapter":"3 Week 1 - Getting started","heading":"3.2 Opening RStudio for the first time","text":"first open RStudio greeted page looks like :double check RStudio opening just R text editor.First thing suggest click File -> New File -> R Script. show normal view get working R.\nfour segments screen:console (Bottom left) - directly running short snippets code, also output errors (sooo many errors) shown.script editor (Top left) - writing longer chunks code able save file.area shows functions objects create (Top right).area shows fancy figures create, also somewhere can navigate files (Bottom right).’ll become intimately aware areas course module want overview sections now video give good introduction section (recommend watching around 5mins 45sec).Finally, basic set , important look cool analysis R. change basic appearance:Click Tools -> Global Options -> Appearance.like Editor Theme Vibrant Ink. makes feel like hacker 90's. Also, getting old like may want make use View -> Zoom option increase size text.Stressed yet? worry, screen looking like time. learning curve R things start click love !","code":""},{"path":"week-1---getting-started.html","id":"packages","chapter":"3 Week 1 - Getting started","heading":"3.3 Packages","text":"basic functions R great, one useful things working R (instead commercial software) ability incorporate user generated content customise able . add-content known packages. validated frequently used packages stored CRAN (Comprehensive R Archive Network) server RStudio knows exactly find , long know name package. need click around random websites downloading files install, nice.module make extensive use tidyverse package. package full frequently used packages R coding, bringing together set grammar visulisation tools makes process writing R whole lot easier.install tidyverse package type following code console (next bottom >) hit enter key run code. can copy paste directly document clicking clipboard icon top right box.ever need install package per computer need load time open RStudio. subsequent times code need:analysis conduct good idea include packages first code script, copy code place top new script (top left screen, created one).run , code, can either highlight code click Run button top right script window. can navigate line want run hit Ctrl+Enter.","code":"\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)"},{"path":"week-1---writing-and-running-your-first-code.html","id":"week-1---writing-and-running-your-first-code","chapter":"4 Week 1 - Writing and running your first code","heading":"4 Week 1 - Writing and running your first code","text":"Okay, lets get coding!","code":""},{"path":"week-1---writing-and-running-your-first-code.html","id":"r-as-an-overpowered-calculator","chapter":"4 Week 1 - Writing and running your first code","heading":"4.1 R as an overpowered calculator","text":"Firstly, R excellent calculator. Take following lines code try running console script window.run code console (bottom left window RStudio) click bottom > symbol, type paste code like run, hit Enter key.run code script window:Make sure script window open, can open new script clicking File -> New File -> R Script.Make sure script window open, can open new script clicking File -> New File -> R Script.Type paste code want run.Type paste code want run.Highlight code click Run navigate line/chunk like run hit Ctrl+Enter (mac Command+Enter)Highlight code click Run navigate line/chunk like run hit Ctrl+Enter (mac Command+Enter)running line code output reported console look something like :[1] beginning output way indexing output. Take following code instance:Running generates set 50 data points normally distributed mean 5 standard deviation 1. creates long output spans multiple lines number [] gives indication many data points displayed line.final line code ran used function, case sqrt function used order perform square root calculation. typing RStudio may noticed typing first three letters box popped rest function short explanation function.super helpful feature RStudio end using lot. {base} indicates function exists within base version R. Later using functions added tidyverse package. worth keeping eye common error trying use function package loaded.Another way learn function running: ?sqrt. loads help file bottom right explains information function.Try running following functions dplyr package included tidyverse package:received error message reads somthing like :documentation ‘mutate’ specified packages libraries:\ntry ‘??mutate’likely due yet installed loaded tidyverse package. install simple run install.packages(\"tidyverse\") console script. Read previous chapter covers packages detail .help files likely confusing moment make lot sense go coding.","code":"\n1+1\n\n4*(14-4)\n\n10^2\n\nsqrt(144)## [1] 2## [1] 40## [1] 100## [1] 12\nrnorm(50, 5, 1)\nlibrary(tidyverse)\n\n?mutate\n?select\n?arrange"},{"path":"week-1---writing-and-running-your-first-code.html","id":"this-is-a-smart-book","chapter":"4 Week 1 - Writing and running your first code","heading":"4.2 This is a \"smart book\"","text":"see blue boxes section ? using throughout book include additional explanation hide solutions exercises can first try work code . Also places include questions allow self-test knowledge. example:square root 36864 Use sqrt() functionThe box turn green input correct number.code use load help file rnorm function? ?rnormIs using AI permitted module? Absolutely , dare !Yes, fact encouraged!","code":""},{"path":"week-1---writing-and-running-your-first-code.html","id":"meet-your-pesonal-r-tutor-chatgpt-or-alternitive","chapter":"4 Week 1 - Writing and running your first code","heading":"4.3 Meet your pesonal R tutor ChatGPT (or alternitive)","text":"Well good time introduce teaching assistant module, ChatGPT (equivalent alternative)Writing code become vastly easier last year public release various Large Language Models (LLMs) AIs. go depth LLMs work (mainly actually know) basic terms LLM artificial intelligence \"trained\" unfathomably large amount language data across internet. previously mentioned, many academic disciplines businesses use R data analyses many guides resources online explaining write code R. Talking LLM like talking someone read, memorised, \"understands\" guides able explain pretty much simple understand way.Personally, use LLM called ChatGPT OpenAI, can set free account just email address. paid version, need using semester. Lately, working AI write apps teaching undergraduate statistics (like ) say makes learning new aspects coding far quicker enjoyable hacking way Google YouTube looking suitable explanations.However, means perfect. biggest limitation currently trained data 2021. Meaning can’t advise changes R (packages) since end training. Also, doesn’t know answer just make stuff confidently present fact (’s lot like respect!). , best never trust completely.chatbot thought nice let ChatGPT introduce , click link see transcript conversation demonstration working AI can R learning.\nSeeing just entered brave new world AI, now, ask use LLMs aid R coding rather written work (doubt heard hugely disruptive ability write essays). stage please use module, lecturers may different preferences like respect. doubt, ask.","code":""},{"path":"week-1---writing-and-running-your-first-code.html","id":"back-to-the-coding","chapter":"4 Week 1 - Writing and running your first code","heading":"4.4 Back to the coding","text":"using R basic calculator basically using sledgehammer crack walnut. Obviously coding R can much . One really important aspect R assigning data object.","code":""},{"path":"week-1---writing-and-running-your-first-code.html","id":"assigning-numbers-to-objects","chapter":"4 Week 1 - Writing and running your first code","heading":"4.4.1 Assigning numbers to objects","text":"Run following code line line. time run line take look environment tab top right window RStudio.first two lines use <- notation (made less < dash -symbols) assign number letter. third line adds value value b creates new object c containing value sum +b. fourth line add three created objects together, look console see output sum.\nfirst instinct likely say ball costs £0.10 answer actually £0.05. can check just learnt assigning values objects. See can adapt code appropriately test . Reassigning value object overrides previous value, can click little broom icon environment window remove previous objects.worry question still hurts brain, even teaching years!Bat + Ball = 1.10Bat = 1.00 + Ball1.00 + 2*Ball = 1.10Ball = (1.10 - 1.00)/2Ball = 0.1 / 2Ball = 0.05","code":"\na <- 5\nb <- 10\n\nc <- a+b\n\na+b+c## [1] 30\n# change out the question mark until you get the correct answer of 1.1\n\nBall <- ?\n\nBat <- Ball + 1.00\n\nBat + Ball "},{"path":"week-1---writing-and-running-your-first-code.html","id":"assigning-multiple-data-point-to-an-object","chapter":"4 Week 1 - Writing and running your first code","heading":"4.4.2 Assigning multiple data point to an object","text":"object can hold just single value. following code range numerical data created, assigned object age. c() function concatenates (fancy word links) values together <- stores single object, case age.assigning data age run age (either console script) list appear output console.Sometimes data want just list consecutive numbers. following lines code equivalent however one substantially quicker , especially scale.can also assign words/letters (known string data) object.might see going , yes can combine objects dataset assign yet another object.can see created new type object environment window, Data object. tells us many observations (case, rows data) many variables (case, columns data). can now view data clicking using view() command.","code":"\nage <- c(23, 57, 42, 12, 8, 92, 35, 86, 26, 65)\nID_number <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nID_number <- 1:10\nnames <- c(\"Kayleigh\", \"Lisa\", \"Beatrice\", \"Jessie\", \"Hugo\", \"Justin\", \"Mohammed\", \"Shawn\", \"Hasan\", \"Kelly\")\n\ngender <- c(\"Female\", \"Female\", \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Non-binary\")\ndata <- data.frame(ID_number, age, names, gender)\n\nview(data)"},{"path":"week-1---writing-and-running-your-first-code.html","id":"video-walkthrough","chapter":"4 Week 1 - Writing and running your first code","heading":"4.5 Video walkthrough","text":"video talking basics working content:\n","code":""},{"path":"week-1---writing-and-running-your-first-code.html","id":"test-yourself-exercises","chapter":"4 Week 1 - Writing and running your first code","heading":"4.6 Test yourself exercises","text":"","code":""},{"path":"week-1---writing-and-running-your-first-code.html","id":"exercise-1","chapter":"4 Week 1 - Writing and running your first code","heading":"4.6.1 Exercise 1","text":"Create dataframe contains data following table:way , achieved results different way. Great, well done!","code":"\nAge <- c(18, 18, 19, 22, 24, 24, 25, 29, 35, 42, 52, 68)\n\nID <- 1:12\n\nGender <- c(\"Female\", \"Female\", \"Male\", \"Female\", \"Male\",\"Female\",\"Non-binary\", \"Male\", \"Male\", \"Male\", \"Female\",\"Non-binary\")\n\nScore <- c(100, 89, 92, 62, 100, 75, 78, 89, 100, 86, 68, 85) \n\ntestscore <- data.frame(ID, Age, Gender, Score)"},{"path":"week-1---writing-and-running-your-first-code.html","id":"exercise-2","chapter":"4 Week 1 - Writing and running your first code","heading":"4.6.2 Exercise 2","text":"Next use rnorm function generate variable called IQ includes data point participant dataset (e.g. whatever N equals). Mean equal 100 can choose realistic standard deviation.R case sensitive double check capatalisation objects throughout.forget can use ?rnorm command open help file rnorm function. show use ., way , achieved results different way. Great, well done!","code":"\nIQ <- rnorm(12, 100, 15)\n\ntestscore <- data.frame(ID, Age, Gender, Score, IQ)"},{"path":"week-1---writing-and-running-your-first-code.html","id":"exercise-3","chapter":"4 Week 1 - Writing and running your first code","heading":"4.6.3 Exercise 3","text":"cup tea biscuit together cost £1.50. cup tea costs £1.30 biscuit. much biscuit cost?Tea + Biscuit = 1.50\nTea = 1.30 + BiscuitAgain, worry, meant counterintuitive question.book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":"\nBiscuit <- 0.1\n\nTea <- Biscuit + 1.30\n\nTea + Biscuit "},{"path":"week-2---basic-visualisation.html","id":"week-2---basic-visualisation","chapter":"5 Week 2 - Basic visualisation","heading":"5 Week 2 - Basic visualisation","text":"","code":""},{"path":"week-2---basic-visualisation.html","id":"introduction","chapter":"5 Week 2 - Basic visualisation","heading":"5.1 Introduction","text":"week, want introduce data visualisation package ggplot2 (contained within tidyverse). ggplot incredibly versatile way creating graphs become standard throughout academic publishing data journalism.link post BBC talking recently moved using ggplot data visualisationsSoon, spotting figures everywhere start saying \"bet recreate ggplot\", get sad find share data :-(following examples exercises, using 2015 country-level summary World Health Organisation data related life expectancy (source). Next week, show read data files now given code imports dataset directly GitHub (web hosting system use book).week need following packages:Remember using packages (e.g. ggrepel) first time need run install.packages(\"packagename\"). often best run console just re-installing package time run code.Note quotation marks around package name. R quite sensitive sort precision , , attention detail ends solving errors get. Either just ask ChatGPT . completely legitimate ways code!worked way content last week, already tidyverse installed likely need install ggrepel.","code":"\n# Run this code to get the data for this week\nlibrary(tidyverse)\n\nwho_rawdata <- read_csv(\"https://raw.githubusercontent.com/RichClarkePsy/Datasets/main/Life%20expectancy%20dataset.csv\") \nlibrary(tidyverse) # contains the ggplot2 package\nlibrary(ggrepel) # used later to add text labels to data points"},{"path":"week-2---basic-visualisation.html","id":"feeling-overwhelmed","chapter":"5 Week 2 - Basic visualisation","heading":"5.1.1 Feeling overwhelmed?","text":"Throughout week going chucks code little clue going . ok! One best ways learn R just play around pre-existing code, change parts see happens. run errors understand, code want explained, just copy paste ChatGPT conversation explain (included example later). can even ask follow questions ask adapt code specifications. Though help know least little code , especially later course move analysis.","code":""},{"path":"week-2---basic-visualisation.html","id":"getting-an-overview-of-your-data","chapter":"5 Week 2 - Basic visualisation","heading":"5.2 Getting an overview of your data","text":"point packages loaded data object top right Environment window named who_rawdata. Just looking data object environment window can see two aspects dataset; number observations number variables. Observations case individual countries variables various health social data variables.\nClick dataset run view(who_rawdata) take look data. , new tab appear view similar :Viewing data like good quick look data, however, health often using datasets many hundreds variables thousands observations. looking data directly much might using SPSS. Instead want get habit exploring dataset code.following gives basic information dataset console. may want increase size console window scroll see full information.viewing output code...variable name life expectancy? Name variable can letters numbers data. known character (chr) data average number years schooling across countries? ","code":"\ndim(who_rawdata)\n\nstr(who_rawdata)\n\nsummary(who_rawdata)"},{"path":"week-2---basic-visualisation.html","id":"visualising-global-life-expectancy","chapter":"5 Week 2 - Basic visualisation","heading":"5.3 Visualising global life expectancy","text":"Statistics great (done undergraduate know love !), often, want get quick easy understanding dataset, can get everything want simple data visualisation.","code":""},{"path":"week-2---basic-visualisation.html","id":"histograms","chapter":"5 Week 2 - Basic visualisation","heading":"5.3.1 Histograms","text":"Histograms good first step towards understanding continuous variable like life expectancy. create histogram going take dataset going pipe %>% ggplot function.pipe basically way saying \"\" code. helps tidy things creating object object. case saying: take data use data following ggplot expression.can done single line code, however, lot neater hit enter pipe start next expression next line. also indents ease navigation. part grammar coding get use time.see code pipes like %>% module |> also job. difference far nerdy us care right now, just know basically thing.book can just adapt code given , get used notation like time.ggplot visualisation made layers. start mapping aesthetic (aes), involves organisation data goes axis data segmented within visualisation. layer (using + sign) geometry combine data desired visual format. following example takes data, places life expectancy x-axis, uses histogram geometry.histogram fine quick exploration data, also tidy figure point perfectly fine include paper.","code":"\nwho_rawdata %>%\n  ggplot(aes(x=Life_exp)) +\n  geom_histogram()\nwho_rawdata %>%\n  ggplot(aes(x=Life_exp)) +\n  geom_histogram(binwidth = 1, \n                 colour = \"black\", \n                 fill = \"#58A139\") +\n  labs(title = \"Figure 1. Histogram of Global Life Expectancy\",\n       subtitle = \"N = 183 countries\",\n       x = \"Life expectancy from birth\",\n       y = \"Number of countries\",\n       caption = \"Year: 2015 | Data source: WHO\") +\n  theme_light() +\n  theme(plot.caption = element_text(hjust = 0.5))"},{"path":"week-2---basic-visualisation.html","id":"test-yourself-exercise-1","chapter":"5 Week 2 - Basic visualisation","heading":"5.3.2 Test yourself exercise 1","text":"Take code adapt work arguments (e.g. \"binwidth\" \"subtitle\") control. Colours can words hex codes. useful website can get hex codes www.htmlcolorcodes.com.keep head times. point Googled pretty much every element .Try searching online following see can find similar looking code:\"Change colour histogram bars ggplot\"\"Add caption ggplot figure\"\"Align caption center ggplot\"Also conversation ChatGPT makes changes final version suggests genuinely helpful additions (dotted gridlines nice touch).","code":""},{"path":"week-2---basic-visualisation.html","id":"facet-wrap","chapter":"5 Week 2 - Basic visualisation","heading":"5.3.3 Facet wrap","text":"good starting visualisation, say want understand distribution region. need add last line code create nicely formatted version six histograms together.~ often used R denote relationship. often see regression analysis case telling ggplot facet (.e. seperate) graph variable Continent.","code":"\nwho_rawdata %>%\n  ggplot(aes(x=Life_exp)) +\n  geom_histogram(binwidth = 1, \n                 colour = \"black\", \n                 fill = \"#58A139\") +\n  labs(title = \"Figure 1. Histogram of Global Life Expectancy\",\n       subtitle = \"N = 183 countries\",\n       x = \"Life expectancy from birth\",\n       y = \"Number of countries\",\n       caption = \"Year: 2015 | Data source: WHO\") +\n  theme_light() +\n  theme(plot.caption = element_text(hjust = 0.5)) +\n  facet_wrap(~ Continent)"},{"path":"week-2---basic-visualisation.html","id":"boxplots","chapter":"5 Week 2 - Basic visualisation","heading":"5.3.4 Boxplots","text":"histograms definitely value (instance can now see difference life expectancy Europe Africa clearly), better way visualise data might change histogram boxplot.Much better, instantly can see distribution life expectancy differs across continents. things spring mind make figure informative.\n1. Label outliers ('d nice know countries ).\n2. Add colour.\n3. Add title label x-axis.first point genuinely quite hard solve involves two lines code .first line creates new function can used identify outliers variable. , next line, use function make new variable evertime function finds outlier Life_exp assigns text Country variable.Also, made change data (case added new variable) assigned new object name, always try keep raw data form read . Just case need use later. Notice new dataframe object environment window running .add outlines figure added layer text box plot layer.points two three selected pre-existing colour pallet mapped Continent variable added labels labs function.Now good looking figure!lot going make figures luckily need keep head one time. often go back old code code webbooks like PsyTeachR adapt change needs.fact lets adapt code BMI instead life expectancy.","code":"\nwho_rawdata %>%\n  ggplot(aes(x=Life_exp, y=Continent)) +\n  geom_boxplot() +\n  theme_light()\nfindoutlier <- function(x) {\n  return(x < quantile(x, .25) - 1.5*IQR(x) | x > quantile(x, .75) + 1.5*IQR(x))\n  }   \n\nwho_with_outliers <- who_rawdata %>% \n  group_by(Continent) %>%\n  mutate(outlier_LE = ifelse(findoutlier(Life_exp), Country, NA)) \nlibrary(ggrepel) # you'll need to install this if you've not already done so\n\nwho_with_outliers %>%\n  ggplot(aes(x=Life_exp, y=Continent, fill = Continent)) +\n  geom_boxplot(width = 0.5,\n               alpha = 0.75,\n               show.legend = FALSE) +\n  geom_text_repel(aes(label=outlier_LE),\n                  position = \"identity\",\n                  size = 3,\n                  na.rm=TRUE) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(title = \"Figure 2. Boxplot of Global Life Expectancy\",\n       subtitle = \"N = 183 countries\",\n       x = \"Life expectancy from birth\",\n       y = \"\",\n       caption = \"Year: 2015 | Data source: WHO\") +\n  theme_light() +\n  theme(plot.caption = element_text(hjust = 0))"},{"path":"week-2---basic-visualisation.html","id":"test-yourself-exercise-2","chapter":"5 Week 2 - Basic visualisation","heading":"5.3.5 Test yourself exercise 2","text":"Adapt code make histogram boxplot BMI variable instead life expectancy.Note: code calculating outliers BMI, requires adding extra line drop_na(BMI). tells R remove missing data variable BMI. Note change dataset name well.running code need start data_BMI file rather rawdata.Look see parts code say Life_exp change BMIMake sure remember change title axes labels.one way histogram look:one way boxplot look:notice data visual check?Personally, concerned low BMI data points, BMI never really low. Perhaps data recording issue. way know without looking individual level data. analysis may want filter data points, least check data sources.","code":"\nfindoutlier <- function(x) {\n  return(x < quantile(x, .25) - 1.5*IQR(x) | x > quantile(x, .75) + 1.5*IQR(x))\n}\n\nwho_BMI <- who_rawdata %>%\n  drop_na(BMI) %>%\n  group_by(Continent) %>%\n  mutate(outlier_BMI = ifelse(findoutlier(BMI), Country, NA)) \nwho_BMI %>%\n  ggplot(aes(x=BMI)) +\n  geom_histogram(binwidth = 1, \n                 colour = \"black\", \n                 fill = \"#58A139\") +\n  labs(title = \"Figure 1. Histogram of Body Mass Index\",\n       subtitle = \"N = 183 countries\",\n       x = \"BMI\",\n       y = \"Number of countries\",\n       caption = \"Year: 2015 | Data source: WHO\") +\n  theme_light() +\n  theme(plot.caption = element_text(hjust = 0.5))\nwho_BMI %>%\n  ggplot(aes(x=BMI, y=Continent, fill = Continent)) +\n  geom_boxplot(width = 0.5,\n               alpha = 0.75,\n               show.legend = FALSE) +\n  geom_text_repel(aes(label=outlier_BMI),\n                  position = \"identity\",\n                  size = 3,\n                  na.rm=TRUE) +\n  scale_fill_brewer(palette = \"Dark2\") +\n  labs(title = \"Figure 3. Boxplot of global BMI\",\n       subtitle = \"N = 181 countries\",\n       x = \"BMI\",\n       y = \"\",\n       caption = \"Year: 2015 | Data source: WHO\") +\n  theme_light() +\n  theme(plot.caption = element_text(hjust = 0))"},{"path":"week-2---basic-visualisation.html","id":"correlation-between-variables","chapter":"5 Week 2 - Basic visualisation","heading":"5.4 Correlation between variables","text":"Next, take look good ggplot making scatter plots. following code plots number years schooling (x-axis) life expectancy (y-axis) 183 countries., takes dataset pipes ggplot. aesthetic years schooling x-axis life expectancy y-axis. geometry layer using geom_point (rather geom_boxplot geom_histogram) creates scatter plot.looks clear correlation . coming weeks look strength statistical significance relationships, now, tidy , can add regression line (adding extra geometry layer geom_smooth), title, label axes.happens change order put geom_smooth geom_point function? dots visableOnly line visableThe dots now appear ontop lineEverything breaks!usually multiple different ways achieve want achieve ggplot.delete bottom two lines code, can find way label x y-axes within labs function?Check code earlier","code":"\nwho_rawdata %>%\n  ggplot(aes(x = Schooling, y = Life_exp)) +\n  geom_point()\nwho_rawdata %>%\n  ggplot(aes(x = Schooling, y = Life_exp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\",\n              formula = y ~ x) +\n  labs(title = \"Figure 2. A scatter plot of life expectancy by number of years of schooling\",) +\n  xlab(label = \"Average number of years of schooling\")+\n  ylab(label = \"Average life expectancy (in years)\")\nwho_rawdata %>%\n  ggplot(aes(x = Schooling, y = Life_exp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\",\n              formula = y ~ x) +\n  labs(title = \"Figure 2. A scatter plot of life expectancy by number of years of schooling\",\n       x = \"Average number of years of schooling\",\n       y = \"Average life expectancy (in years)\") "},{"path":"week-2---basic-visualisation.html","id":"adding-to-the-aestetic","chapter":"5 Week 2 - Basic visualisation","heading":"5.4.1 Adding to the aestetic","text":"one extra thing can aesthetics part code scatter plot assign colour size data points.code uses Continent variable assign colour.code uses Population variable assign size data points. Now, larger population larger dot size.comments code also indicate parts AI assistants. remember make changes top head. Googleing taken 15 mins find right guide right code requests ChatGPT took less minute also gave explanation extra code works. also great example little AI needs work asking.","code":"\nwho_rawdata %>%\n  ggplot(aes(x = Schooling, y = Life_exp, colour = Continent)) +\n  geom_point() +\n  geom_smooth(aes(group = 1), method = \"lm\", \n              formula = y ~ x, colour = \"black\") +\n  labs(title = \"Figure 3. A scatter plot of life expectancy by number of years of schooling\",\n       x = \"Average number of years of schooling\",\n       y = \"Average life expectancy (in years)\") # delete aes(group = 1) & ,colour = \"black\" to see why I included them\nwho_rawdata %>%\n  ggplot(aes(x = Schooling, y = Life_exp, colour = Continent, size = Population)) +\n  geom_point() +\n  geom_smooth(aes(group = 1), method = \"lm\", formula = y ~ x, colour = \"black\") +\n  labs(title = \"Figure 3. A scatter plot of life expectancy by number of years of schooling\",\n       x = \"Average number of years of schooling\",\n       y = \"Average life expectancy (in years)\") +\n  guides(size = FALSE) # delete this line to see why I included it "},{"path":"week-2---basic-visualisation.html","id":"test-yourself-exersise-3","chapter":"5 Week 2 - Basic visualisation","heading":"5.5 Test yourself exersise 3","text":"Gapminder organisation one time favourite non-profits. mission promote fact-based worldview everyone can understand. Never seen data demography global helath issues communicated engaging way. instance, best 5 minutes data communication ever seen. Sadly, lost amazing Hans Rosling 2017 son daughter--law continue incredible work area worth following.Gapminder created R package contains data similar data just using. Install package, load package, import data using code .looking data can likely see lot time. due also year variable. code just extracts data recent year dataset, 2007.Now play data! Try adapt code week see can produce. list things try:Create histograms life expectancy GDP.Create boxplots life expectancy GDP.Create simple scatter plot life expectancy GDP.Add continent population size data scatter plot 3.Make sure appropriate title axis.Good luck, feel free share create module teams area.","code":"\ninstall.packages(\"gapminder\")\n\nlibrary(gapminder)\n\ngapminder_data <- gapminder::gapminder\ngapminder_2007 <- gapminder_data %>%\n  filter(year == 2007)"},{"path":"week-2---basic-visualisation.html","id":"video-walkthrough-1","chapter":"5 Week 2 - Basic visualisation","heading":"5.6 Video walkthrough","text":"book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":""},{"path":"week-3---working-with-data-files.html","id":"week-3---working-with-data-files","chapter":"6 Week 3 - Working with data files","heading":"6 Week 3 - Working with data files","text":"","code":""},{"path":"week-3---working-with-data-files.html","id":"introduction-1","chapter":"6 Week 3 - Working with data files","heading":"6.1 Introduction","text":"aim week reproduce figure Bravo-Gutierrez et al (2021). figure shows percentage methylation two genes, AHRR (fig. 2a) PRSS23 (fig. 2b), compared across smokers non-smokers. genetics aspect might confusing (least us psychologists) statistics basic (Mann-Whitney U test). authors found significant difference across methylation AHRR gene smokers non-smokers (p=0.003), significantly lower levels methylation smokers (indicating suggested hypomethylation effect smoking AHRR gene), significant difference methylation across PRSS23 gene (p=0.276).authors paper made data study open access (good scientists !), code. replicate analyse see can find findings create image.Download data supplemental materials bottom paper weeks section NS7154 Moodle area.week need following packages. needed, check previous weeks install load packages.","code":"\nlibrary(tidyverse)\nlibrary(ggpubr) # to add p-values to our graphs"},{"path":"week-3---working-with-data-files.html","id":"reading-data-into-r-from-a-data-file","chapter":"6 Week 3 - Working with data files","heading":"6.2 Reading data into R from a data file","text":"Data often messy, especially true data collect , especially especially true data academics share online. Thankfully, data shared paper nice neat tidy, need take steps get R.","code":""},{"path":"week-3---working-with-data-files.html","id":"setting-your-working-directory","chapter":"6 Week 3 - Working with data files","heading":"6.2.1 Setting your working directory","text":"time start analysis R recommend create new folder. Put data want analyses folder. Open script save script newly created folder along data.everything place, back RStudio, set working directory clicking Session -> Set Working Directory -> Choose Directory Source File Location select chosen folder.allows R know look want import data, also save outputs. may seem like redundant step just making couple plots, projects become complicated kind workflow becomes invaluable.","code":""},{"path":"week-3---working-with-data-files.html","id":"file-formats-and-reading-in-the-data","chapter":"6 Week 3 - Working with data files","heading":"6.2.2 File formats and reading in the data","text":"Excel, open file downloaded supplemental materials Bravo-Gutierrez et al 2021. see four tabs bottom Excel window. possible directly read Excel files RStudio, sake simplicity, going convert specific tab interested Comma-Separated Values (CSV) file. CSV file simply text file values dataset separated commas.data tab S4 luckily lovely state just requires us navigate S4 tab, click save select CSV drop \"save type\" menu. Save folder created previously.continuing, take quick look tabs file. Tab one looks intimidating, just two screen shots online gene database. tabs S2 S3 scare (least take get usable form). scroll either tabs see headers repeat data neatly line find SPSS file. Carry R learn work , even messier, kind data, convert known tidy data.","code":""},{"path":"week-3---working-with-data-files.html","id":"reading-data-into-rstudio","chapter":"6 Week 3 - Working with data files","heading":"6.2.3 Reading data into RStudio","text":"long set working directory (loaded tidyverse package) following code, adapted file name, read data RStudio assign object.typing code paying attention autocompleate may noticed read.csv additional option. read.csv function comes base R, read_csv readr package, part tidyverse. requires extra step install load read_csv worth three reasons:Unlike read.csv, read_csv convert character strings factors default. gives control data read interpreted.read_csv returns tibbles rather traditional data frames. may seem identical, tibbles several advantages make work better rest tidyverse packages. instance, tibbles retain data type column, convert character vectors factors default, improved printing methods.read_csv handles missing values (NAs) straightforward manner makes data cleaning manipulation processes easier.dullest note whole book? Maybe, least feel strong contender.","code":"\nraw_data <- read_csv(\"Bravo-Gutierrez figure 2 data.csv\")"},{"path":"week-3---working-with-data-files.html","id":"test-yourself","chapter":"6 Week 3 - Working with data files","heading":"6.2.4 Test yourself","text":"working directory ? location computer RStudio runs accesses filesIt gives extra RAM analyse data quicklyIt changes colour theme RStudioWhat CSV file? file specially made use RA general use text file storing tabular data, separated commasA file storing supplementary figures paperIf run code, type view data file window? Can read SPSS file R? program dead us now. Never speak letters !Yes, check Haven package topic","code":""},{"path":"week-3---working-with-data-files.html","id":"data-wrangling","chapter":"6 Week 3 - Working with data files","heading":"6.3 Data wrangling","text":"Data wrangling refers process cleaning, structuring, enriching raw data suitable format analysis. dplyr package (contained tidyverse) particularly useful contains range six functions known Wickham Six.\nWickham Six:filter() - function used select rows dataset based values.select() - function used choose specific columns dataset, potentially dropping others.mutate() - function used create new columns dataset functions existing columns (.e. computing latent variable individual questionnaire items).arrange() - function used reorder rows dataset based values one several columns.summarise() - function used generate summary statistics different columns dataset.group_by() - function, often used summarise(), group data certain criteria generating summary statistics.functions powerful provide building blocks data wrangling R. chaining functions together using pipes (%>%), can perform complex data manipulations clean, readable, efficient manner.week using select(), mutate(), group_by() summarise(), using lot throughout module may want note sticky note attach screen. first learning.","code":""},{"path":"week-3---working-with-data-files.html","id":"selecting-variables-for-our-analysis","chapter":"6 Week 3 - Working with data files","heading":"6.3.1 \"Selecting\" variables for our analysis","text":"Looking back figure description paper actually need three variables dataset create boxplots. , first thing tidy dataset pulling variables putting new object called fig2_data.code uses select() function, takes variables Sample_ID, %5mc-AHRR & %5mc-PRSS23 raw data assigns new object called fig2_data.Variable names can bit fiddly times. Typically start letter free spaces. Often, importing sources, rule adhered . cope R assigns variable flanked back-ticks can seen %5mc-AHRR %5mc-PRSS23 code .Now view() data check variables mentioned. also check using str() functionYou may noticed [number]e+/-n notation data. context, e notation, also known scientific notation, used represent numbers large small conveniently written decimal form. data R variable exceptionally large small (case, small), entire variable displayed scientific notation. may initially seem confusing, quite simple - instance, 1.000000e+2 just means number 100. Consider fun little quirk R get accustomed time.play around code see can select variables assign different data object. skill super helpful assignment, allow just work variables interest, instead hacking way 2000 variable file time want run analysis.","code":"\nfig2_data <- raw_data %>%\n  select(Sample_ID, `%5mc-AHRR`,`%5mc-PRSS23`)"},{"path":"week-3---working-with-data-files.html","id":"mutating-the-sample-id-variable","chapter":"6 Week 3 - Working with data files","heading":"6.3.2 \"Mutating\" the Sample ID variable","text":"look Sample_ID variable dataset, see variable variable indicates participant non-smoker (NS) smoker (S), however, also lumps information next participant ID number, ideal.bad-old-days likely gone hand, converting ID variable grouping variable. much issue particular dataset, just imagine dataset thousands participants! Luckily, can conversion line code using mutate() function.number ways , way example:first line tells R just overwrite data object whatever next. use mutate function create new variable. variable called quasi_condition (independent variable quasi-experimental) told R look start string data variable Sample_ID letters \"NS\" first write \"Non-Smoker\" new variable, letter \"S\" first write \"Smoker\" new variable.: fig2_data <- fig2_data risky. kind thing can really mess code, especially overwrite raw data. seen disasters SPSS students kept single save file reverse-coded variable, return file later date. Forgetting already reverse-coded, inadvertently reverse . Although less chance , thanks coding script, still careful complicated projects. Data manipulation can become confusing can potentially lead unintended consequences.clean variable names, using rename function .progress R want/need code neat tidy. code single expression thanks piping (%>%):view(fig2_data) now see new variable created smoker/non-smoker information variable names easier handle.","code":"\nfig2_data <- fig2_data %>%\n  mutate(quasi_condition = case_when(str_starts(Sample_ID, \"NS\") ~ \"Non-Smoker\",\n                                     str_starts(Sample_ID, \"S\") ~ \"Smoker\")) \nfig2_data <- fig2_data %>%\n  rename(AHRR = `%5mc-AHRR`,\n         PRSS23 = `%5mc-PRSS23`)\nfig2_data <- raw_data %>%\n  select(Sample_ID, `%5mc-AHRR`,`%5mc-PRSS23`) %>%\n  mutate(quasi_condition = case_when(str_starts(Sample_ID, \"NS\") ~ \"Non-Smoker\",\n                                     str_starts(Sample_ID, \"S\") ~ \"Smoker\")) %>%\n  rename(AHRR = `%5mc-AHRR`,\n         PRSS23 = `%5mc-PRSS23`)"},{"path":"week-3---working-with-data-files.html","id":"grouping-and-summarising-the-data","chapter":"6 Week 3 - Working with data files","heading":"6.3.3 \"Grouping\" and \"Summarising\" the data","text":"code takes fig2_data object, groups new condition variable, uses summarise function (confused summary function) give us number participants mean, median, standard deviation just AHRR variable split smokers non-smokers.also missing data added na.rm = TRUE arguments. come back deal missing data later weeks.take look output console, can see compares figure original paper (see top page). Boxplots thick black line median data smokers medium 47 non-smokers medium 100 looks good .","code":"\nfig2_data %>%\n  group_by(quasi_condition) %>%\n  summarise(N = n(), \n            Mean = mean(AHRR, na.rm = TRUE), \n            Median = median(AHRR, na.rm = TRUE), \n            SD = sd(AHRR, na.rm = TRUE))"},{"path":"week-3---working-with-data-files.html","id":"recreating-the-figure","chapter":"6 Week 3 - Working with data files","heading":"6.3.4 Recreating the figure","text":"Next can pipe data ggplot create basic boxplot AHRR methylation variable separated quasi_condition independent variable.turn final figure need following:Sorry, one probably felt little like :However, amazing now ChatGPT. Click link see great AI explaining code.","code":"\nfig2_data %>%\n  ggplot(aes(x=quasi_condition, y=AHRR)) +\n  geom_boxplot()\nmy_comparisons <- list(c(\"Smoker\", \"Non-Smoker\"))\n\nfig2_data %>%\n  ggplot(aes(x=quasi_condition, y=AHRR, fill=quasi_condition)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette=\"Dark2\") +\n  stat_compare_means(comparisons = my_comparisons) +\n  geom_jitter(width = .25) + \n  ylab(label = \"%5mc-cg05575921\") +\n  theme(legend.position = \"none\")"},{"path":"week-3---working-with-data-files.html","id":"video-walkthrough-2","chapter":"6 Week 3 - Working with data files","heading":"6.4 Video walkthrough","text":"","code":""},{"path":"week-3---working-with-data-files.html","id":"test-yourself-exercise","chapter":"6 Week 3 - Working with data files","heading":"6.5 Test yourself exercise","text":"Create new script see can follow wrangling steps , time create:dataframe containing summary statistics PRSS23 geneA boxplot close Figure 2b original paper can.Note: match exactly need add additional line code re-scale y-axis:\nscale_y_continuous(limits=c(0, 10), name = \"PRSS23\"):Yes, annoyed missing p-value adjust y-axis.think calculated p-values separately added text geom. explain slightly different p-value roundings.Next tidy figure \n1. Adding title.\n2. Removing label quasi_conditions.\n3. Changing colour scheme.\n4. Changing amount jitter.Check back code last week.book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":"\nfig2b_discriptives <- fig2_data %>%\n  group_by(quasi_condition) %>%\n  summarise(N = n(), \n            Mean = mean(PRSS23, na.rm = TRUE), \n            Median = median(PRSS23, na.rm = TRUE), \n            SD = sd(PRSS23, na.rm = TRUE))\n\nmy_comparisons <- list(c(\"Smoker\", \"Non-Smoker\"))\n\nfig2_data %>%\n  ggplot(aes(x=quasi_condition, y=PRSS23, fill=quasi_condition)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette=\"Dark2\") +\n  stat_compare_means(comparisons = my_comparisons) +\n  geom_jitter(width = .25) + \n  theme(legend.position = \"none\")\nfig2_data %>%\n  ggplot(aes(x=quasi_condition, y=PRSS23, fill=quasi_condition)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette=\"Dark2\") +\n  stat_compare_means(comparisons = my_comparisons) +\n  scale_y_continuous(limits=c(0, 10), name = \"PRSS23\") +\n  geom_jitter(width = .25) + \n  theme(legend.position = \"none\")\nfig2_data %>%\n  ggplot(aes(x=quasi_condition, y=PRSS23, fill=quasi_condition)) +\n  geom_boxplot() +\n  scale_fill_viridis_d() +\n  stat_compare_means(comparisons = my_comparisons) +\n  geom_jitter(width = .1) + \n  ggtitle(label = \"Figure 2. Methylation percentage between smokers and non-smokers.\") +\n  ylab(label = \"PRSS23\") +\n  xlab(label = \"\")+\n  theme(legend.position = \"none\")"},{"path":"week-4---working-with-catagorical-variables.html","id":"week-4---working-with-catagorical-variables","chapter":"7 Week 4 - Working with catagorical variables","heading":"7 Week 4 - Working with catagorical variables","text":"week, take first steps towards working assignment dataset looking similar dataset 2019.Download files Week4_data_shes19.csv Codebook.csv week's Moodle area. Save folder fresh R analysis script, set folder working directory. read data codebook RStudio take initial look .dataset :Check missing data.Select() filter() data manageable segments.Dichotomies continuous variables.Create summary statistics use descriptive statistics table.week need following packages. forget, used package previously need run install.package(\"packagename\") new package.set working directory click Session -> Set Working Directory -> Choose Directory (navigate folder) Source File Location.load data, first make sure loaded tidyverse package. , read data:Hopefully, now see dataset environment window comprising 33 variables impressive 6881 observations (participants) - manual recoding certainly going feasible volume data!dataset small selection key variables Scottish Health Survey 2019. Accompanying main dataset auxiliary file - codebook. execute view(Codebook) Codebook %>% print(n=33), find dataframe composed two variables provide insight meanings variable name. cases, even clarify exact question asked participants.variable Cigwend represent? Time spent smoking cigarettes weekend daysWeekend goals quit cigarettesNumber cigarettes smoked weekend daysWhat exact variable name Index Multiple Deprivation statistic used survey ","code":"\nlibrary(tidyverse)\nlibrary(scales) # useful for scaling and formatting data\nraw_data <- read_csv(\"Week4_data_shes19.csv\")\nCodebook <- read_csv(\"Codebook.csv\")"},{"path":"week-4---working-with-catagorical-variables.html","id":"missing-data","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.1 Missing data","text":"Massive surveys prone missing data issues. majority cases 2019 datasets (2021 assignment dataset) missing data due different waves survey asking different questions collecting different data.\ndataset, seven different ways missing data labelled. code cleans just labels types missing data NA, stands Applicable. Add script run now.Simple explanation:code generates object named missing_values containing different words used identify missing data dataset. , applies mutate_all function raw data. function replaces occurrences values listed object missing_values entire dataframe NA. assigns object cleaned_data.Deeper explanation:~ symbol ~replace(., . %% missing_values, NA) piece R code used create lambda function, --fly function meant one-time use, . acts placeholder data processed. lambda function applied every column dataframe mutate_all(), replacing element found missing_values NA.simplified example:example, ~ .^2 lambda function. ~ symbol tells R follows formula, . placeholder represents current column data processed.Now, see damage , many missing values dealing ?forget every come across code understand can always use ? find function. example run following:plain language explanation ask AI choice. explanation ChatGPT gave code.course, Google also option. just finding AI quicker days.many missing values variable UniCredit? exact variable name variable missing data? second question probably lead looking data trying work number highest. Sounds like inefficient use time . exactly kind thing trying get away move R. use code make task easier, scalable, less prone error.Seeing missing data data object, need now arrange() dataset descending order top variable view data object one missing data.make life even easier graph :","code":"\nmissing_values <- c(\"Unclassifiable\", \"Refused\", \"Don't know\", \n                    \"Schedule not obtained\", \"Schedule not applicable\", \"Not applicable\", \"Reading not obtained\")\n\ncleaned_data <- raw_data %>%\n  mutate_all(~replace(., . %in% missing_values, NA))\ndf <- data.frame(a = 1:3, b = 4:6)\ndf_squared <- df %>% mutate_all(~ .^2)\nmissing_data <- cleaned_data %>%\n  summarise_all(~sum(is.na(.))) %>% \n  pivot_longer(cols = 1:33, names_to = \"Variables\", values_to = \"NAs\") %>%\n  print(n=33)\n?summarise_all\n?pivot_longer\n?print\nmissing_data <- missing_data %>%\n  arrange(desc(NAs))\nmissing_data %>%\n  arrange(NAs) %>%\n  ggplot(aes(x = NAs, y = reorder(Variables, NAs))) +\n  geom_col()"},{"path":"week-4---working-with-catagorical-variables.html","id":"preparing-data-for-analysis","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.2 Preparing data for analysis","text":"Next, take closer look participants readings Diastolic Systolic blood pressure. obtain data, -person visit likely required, surprise fair amount missing data. However, even missing data still looks like 1000 participants readings, excellent. Just think many hours take us collect amount data!prepare data analysis, need reoganise data little using various functions, filter(), mutate(), select().","code":""},{"path":"week-4---working-with-catagorical-variables.html","id":"filter-relevant-cases","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.2.1 Filter relevant cases","text":"filter() function need used select data missing data Systolic Diastolic variables.filter() function really useful extra language (logical operators) need learn (just learn find use) use full effect. full list definition:> (Greater ): operator returns TRUE value left greater value right. example, filter(Age > 18) keep rows Age greater 18.> (Greater ): operator returns TRUE value left greater value right. example, filter(Age > 18) keep rows Age greater 18.< (Less ): operator returns TRUE value left less value right. example, filter(Age < 18) keep rows Age less 18.< (Less ): operator returns TRUE value left less value right. example, filter(Age < 18) keep rows Age less 18.>= (Greater Equal ): operator returns TRUE value left greater equal value right. example, filter(Age >= 18) keep rows Age 18 older.>= (Greater Equal ): operator returns TRUE value left greater equal value right. example, filter(Age >= 18) keep rows Age 18 older.<= (Less Equal ): operator returns TRUE value left less equal value right. example, filter(Age <= 18) keep rows Age 18 younger.<= (Less Equal ): operator returns TRUE value left less equal value right. example, filter(Age <= 18) keep rows Age 18 younger.== (Equal ): operator returns TRUE value left equal value right. example, filter(Age == 18) keep rows Age exactly 18. common mistake use just one equals sign. common fact tailored error message read \"mean ==?\" used incorrectly.== (Equal ): operator returns TRUE value left equal value right. example, filter(Age == 18) keep rows Age exactly 18. common mistake use just one equals sign. common fact tailored error message read \"mean ==?\" used incorrectly.& (): operator returns TRUE left right operands TRUE. example, filter(Age > 18 & Income > 50000) keep rows age greater 18 variable Income greater 50,000.& (): operator returns TRUE left right operands TRUE. example, filter(Age > 18 & Income > 50000) keep rows age greater 18 variable Income greater 50,000.| (): operator returns TRUE either () operands TRUE. example, filter(Age < 18 | Income > 50000) keep rows age less 18 income greater 50,000.| (): operator returns TRUE either () operands TRUE. example, filter(Age < 18 | Income > 50000) keep rows age less 18 income greater 50,000.! (): operator negates truth value operand. example, filter(!.na(Age)) keep rows Age NA.! (): operator negates truth value operand. example, filter(!.na(Age)) keep rows Age NA.!= (Equal ): operator returns TRUE value left equal value right. example, filter(Age != 18) keep rows Age 18.!= (Equal ): operator returns TRUE value left equal value right. example, filter(Age != 18) keep rows Age 18.following code filters rows (&) Systolic Diastolic include missing data (!.na).","code":"\nBP_data <- cleaned_data %>%\n  filter(!is.na(Systolic) & !is.na(Diastolic))"},{"path":"week-4---working-with-catagorical-variables.html","id":"additional-tidying","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.2.2 Additional tidying","text":"run str(cleaned_data) see variable either chr num next . represents variables data type, chr stands character data (e.g. strings text can numbers characters) num stands numeric data(e.g. string numbers).imported data, Systolic Diastolic data variables used numbers BP readings also contained two types text response \"applicable\" \"Reading obtained\", recoded NA. left us just numerical data, however, seeing text present first read data variables initially assigned character (chr) data.means want use data numeric data need convert number (num) data. code uses mutate() overwrite Systolic Diastolic variables data treated, function implies, numeric type data.Finally, might worth using select() function take variables use analysis. case take variables Age, Sex, SIMD, UrbanRural, Systolic Diastolic. select() also lets us organise order variables depending order list .potentially long line code, select function , wanted many variables often use line break list one . One great features RStudio ability automatically handle text alignment. capability enhances code readability can also act helpful tool error detection, discrepancies might result unusual indentation.following expressions functionally sameTidy code easy read:Horrifying code, probably written psychopath:","code":"\nBP_data <- cleaned_data %>%\n  filter(!is.na(Systolic) & !is.na(Diastolic)) %>%\n  mutate(Systolic = as.numeric(Systolic),\n         Diastolic = as.numeric(Diastolic))%>%\n  select(ID, Age, Sex, SIMD, UrbanRural, Systolic, Diastolic)\nBP_data <- cleaned_data %>%\n  filter(!is.na(Systolic) & !is.na(Diastolic)) %>%\n  mutate(Systolic = as.numeric(Systolic),\n         Diastolic = as.numeric(Diastolic))%>%\n  select(ID, \n         Age, \n         Sex, \n         SIMD, \n         UrbanRural, \n         Systolic, \n         Diastolic)\nBP_data <- cleaned_data %>% filter(!is.na(Systolic) & !is.na(Diastolic)) %>% mutate(Systolic = as.numeric(Systolic), Diastolic = as.numeric(Diastolic))%>% select(ID, Age,Sex,SIMD,UrbanRural,Systolic,Diastolic)"},{"path":"week-4---working-with-catagorical-variables.html","id":"visual-representation-using-catagorical-data","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.3 Visual representation using catagorical data","text":"Quite often blood pressure data want use data work someone dangerously high blood pressure, diagnoses Hypertension. cut point considered 140mmHg Systolic 90mmHg Diastolic measurements NHSBelow scatter plot diastolic systolic blood pressure data. dotted purple line systolic cut high blood pressure dotted red line diastolic blood pressure cut high blood pressure. , want assign label hypertension data points purple line right red line.following code creates new variable, using mutate() function. variable named BP_cat uses if_else function says Systolic 140 (denoted |) Diastolic 90, TRUE, assign \"Hypertension\", else assign \"Normal BP range\".nice thing kind problem can check scatter plot assigning new variable colour aesthetic.Hopefully, looking graph can see problematic hard cut like can health statistics.","code":"\nBP_data %>%\n  ggplot(aes(x = Diastolic, y = Systolic)) +\n  geom_point() +\n  geom_vline(xintercept = 90, linetype = \"dotted\", color = \"red\", size = 1) +  \n  geom_hline(yintercept = 140, linetype = \"dotted\", color = \"purple\", size = 1) +\n  labs(title = \"Scatter Plot of Systolic and Diastolic Blood Pressure\",\n       x = \"Diastolic Blood Pressure\",\n       y = \"Systolic Blood Pressure\")\nBP_data_labelled <- BP_data %>%\n  mutate(BP_cat = if_else(Systolic > 140 | Diastolic > 90, \n                          \"Hypertension\", \n                          \"Healthy BP range\"))\nBP_data_labelled %>%\n  ggplot(aes(x = Diastolic, y = Systolic, colour = BP_cat)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of Systolic and Diastolic Blood Pressure\",\n       x = \"Diastolic Blood Pressure\",\n       y = \"Systolic Blood Pressure\") +\n  scale_color_discrete(name = \"BP Categories\")"},{"path":"week-4---working-with-catagorical-variables.html","id":"discriptive-statistics-tables-for-catagorical-data","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.4 Discriptive statistics tables for catagorical data","text":"One common uses categorical data segment data frequency table.following code groups data two variables interest, case newly created blood pressure categorical variable Sex variableWe can just adapt code another variableFor now, might easier view date object, copy data create APA-formatted table Microsoft Word. However, becoming like obsessed absolutely everything R, bit work, can create tables ready publication right RStudio.process takes effort might worth single table. However, ever create monthly reports, sort automated workflow save significant time future.Also, likely far easier way done . find one, please let know!","code":"\npercentage_Sex_data2 <- BP_data_labelled %>%\n  group_by(Sex, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01))\n\n# Note: the percent function requires the \"scales\" package\npercentage_UR_data <- BP_data_labelled %>%\n  group_by(UrbanRural, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01))\n# this table was created using the \"gt\" package. Install it just as you would any other package.  \n\nlibrary(gt)\n\n# The following wrangles the data into the right formation for the table \n\npercentage_Sex_data <- BP_data_labelled %>%\n  group_by(Sex, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01)) %>%\n  pivot_wider(names_from = \"BP_cat\", values_from = c(Count, Percentage))%>%\n  mutate(Stat_Healthy = paste(`Count_Healthy BP range`, \" (\", `Percentage_Healthy BP range`, \")\", sep=\"\")) %>%\n  mutate(Stat_Hyper = paste(Count_Hypertension, \" (\", Percentage_Hypertension, \")\", sep=\"\"))%>%\n  rename(variable = Sex) %>%\n  mutate(variable_name = \"Sex\")\n  \npercentage_UR_data <- BP_data_labelled %>%\n  group_by(UrbanRural, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01)) %>%\n  pivot_wider(names_from = \"BP_cat\", values_from = c(Count, Percentage)) %>%\n  mutate(Stat_Healthy = paste(`Count_Healthy BP range`, \" (\", `Percentage_Healthy BP range`, \")\", sep=\"\")) %>%\n  mutate(Stat_Hyper = paste(Count_Hypertension, \" (\", Percentage_Hypertension, \")\", sep=\"\"))%>%\n  rename(variable = UrbanRural) %>%\n  mutate(variable_name = \"Location\")  \n\ntable1_data <- rbind(percentage_Sex_data, percentage_UR_data) %>%\n  select(variable_name, variable, Stat_Healthy, Stat_Hyper)\n\n# Note: it is really important to get the group_by vaiable in the right order. See what happens when you flip them. \n\n# the following uses the gt package to create a table in APA style. \ngt(table1_data, groupname_col = \"variable_name\") %>%\n  tab_header(title = md(\"**Table 1**\"),\n             subtitle = md(\"Demographic statistics by blood pressure catagories\")) %>%\n  opt_align_table_header(align = \"left\") %>%\n  cols_label(variable = \" \",\n    Stat_Healthy = md(\"**Healty BP Range <br> n(%)**\"),\n    Stat_Hyper = md(\"**Hypertention <br> n(%)**\")) %>%\n  tab_options(table.border.top.color = \"white\",\n              heading.title.font.size = px(16),\n              column_labels.border.top.width = 3,\n              column_labels.border.top.color = \"black\",\n              column_labels.border.bottom.width = 3,\n              column_labels.border.bottom.color = \"black\",\n              table_body.border.bottom.color = \"black\",\n              table.border.bottom.color = \"white\",\n              table.width = pct(50),\n              table.background.color = \"white\") %>%\n  cols_align(align=\"center\") %>%\n  tab_style(style = list(cell_borders(sides = c(\"top\", \"bottom\"),\n                                      color = \"white\",\n                                      weight = px(1)),\n                         cell_text(align=\"center\"),\n                         cell_fill(color = \"white\", alpha = NULL)),\n            locations = cells_body(columns = everything(),\n                                   rows = everything()))"},{"path":"week-4---working-with-catagorical-variables.html","id":"video-walkthrough-3","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.5 Video walkthrough","text":"","code":""},{"path":"week-4---working-with-catagorical-variables.html","id":"test-yourself-exercises-1","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6 Test yourself exercises:","text":"","code":""},{"path":"week-4---working-with-catagorical-variables.html","id":"exercise-1-1","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6.1 Exercise 1","text":"Dichotomise age variable using median split.Take medium variable assign equal median \"Young\" greater medium \"Old\".likely number ways find medium data. find summary function quickest.need use if_else within mutate function create new variable young old labels. Look back code earlier adapt accordingly.","code":"\nBP_data_labelled %>%\n  select(Age) %>%\n  summary()\n\nage_data_labelled <- BP_data_labelled %>%\n  mutate(age_cat = if_else(Age <= 54, \"Young\", \"Old\"))"},{"path":"week-4---working-with-catagorical-variables.html","id":"exercise-2-1","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6.2 Exercise 2","text":"Create plot Diastolic compared Systolic colour indicating either \"Old\" \"Young\" participant.Look back code plot created Hypertension Health BP Range. Substitute new variable (named mine age_cat) variable used dichotomise BP.","code":"\nage_data_labelled %>%\n  ggplot(aes(x = Diastolic, y = Systolic, colour = age_cat)) +\n  geom_point() +\n  labs(title = \"Scatter Plot of Systolic and Diastolic Blood Pressure\",\n       x = \"Diastolic Blood Pressure\",\n       y = \"Systolic Blood Pressure\")"},{"path":"week-4---working-with-catagorical-variables.html","id":"exercise-3-1","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6.3 Exercise 3","text":"Create descriptive statistics hypertension new dicotomised age variable.","code":"\npercentage_age_data <- age_data_labelled %>%\n  group_by(age_cat, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01))"},{"path":"week-4---working-with-catagorical-variables.html","id":"exercise-4","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6.4 Exercise 4","text":"Create multiple age ranges .e. <18, 18 - 30, 31 - 40, 41 - 50, 51 - 60, 60+ rerun descriptive statistics. need investigate use case_when function.","code":"\nBP_data_labelled2 <- BP_data_labelled %>%\n  mutate(age_cat = case_when(\n  Age < 18 ~ \"<18\",\n  Age >= 18 & Age <= 30 ~ \"18-30\",\n  Age > 30 & Age <= 40 ~ \"31-40\",\n  Age > 40 & Age <= 50 ~ \"41-50\",\n  Age > 50 & Age <= 60 ~ \"51-60\",\n  Age > 60 ~ \"60+\"\n))\n\npercentage_age_data <- BP_data_labelled2 %>%\n  group_by(age_cat, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01))"},{"path":"week-4---working-with-catagorical-variables.html","id":"exercise-5","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6.5 Exercise 5","text":"Create count percentages Scottish Index Multiple Deprivation variable.","code":"\npercentage_SIMD_data <- BP_data_labelled2 %>%\n  group_by(SIMD, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01))"},{"path":"week-4---working-with-catagorical-variables.html","id":"exercise-6-very-much-optional-just-for-fun","chapter":"7 Week 4 - Working with catagorical variables","heading":"7.6.6 Exercise 6 (very much optional / just for fun)","text":"Create table includes frequency percentage health hypertensive participants Sex, UrbanRural, Age SIMD.find quicker easier way please let know!look table2_data data frame see SIMD variables order. annoying. order want :\"deprived\" (areas highest levels deprivation).\"2nd\" second deprived.\"3rd\" third deprived.\"4th\" fourth deprived.\"Least deprived\" (areas lowest levels deprivation).following code, creates new data object order want variables joins SIMD object contains percentages, arranges custom order. Typically, just rework earlier code run kind problem.following code creates APA style table using gt package.thing change table1_data table2_data change title \"Table 2\". may need click Zoom view table full glory.book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":"\n# copied from earlier table code\npercentage_Sex_data <- BP_data_labelled2 %>%\n  group_by(Sex, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01)) %>%\n  pivot_wider(names_from = \"BP_cat\", values_from = c(Count, Percentage))%>%\n  mutate(Stat_Healthy = paste(`Count_Healthy BP range`, \" (\", `Percentage_Healthy BP range`, \")\", sep=\"\")) %>%\n  mutate(Stat_Hyper = paste(Count_Hypertension, \" (\", Percentage_Hypertension, \")\", sep=\"\"))%>%\n  rename(variable = Sex) %>%\n  mutate(variable_name = \"Sex\")\n\n# copied from earlier table code  \npercentage_UR_data <- BP_data_labelled2 %>%\n  group_by(UrbanRural, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01)) %>%\n  pivot_wider(names_from = \"BP_cat\", values_from = c(Count, Percentage)) %>%\n  mutate(Stat_Healthy = paste(`Count_Healthy BP range`, \" (\", `Percentage_Healthy BP range`, \")\", sep=\"\")) %>%\n  mutate(Stat_Hyper = paste(Count_Hypertension, \" (\", Percentage_Hypertension, \")\", sep=\"\"))%>%\n  rename(variable = UrbanRural) %>%\n  mutate(variable_name = \"Location\")  \n\n# code adapted for age \n\npercentage_age_data <- BP_data_labelled2 %>%\n  group_by(age_cat, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01)) %>%\n  pivot_wider(names_from = \"BP_cat\", values_from = c(Count, Percentage)) %>%\n  mutate(Stat_Healthy = paste(`Count_Healthy BP range`, \" (\", `Percentage_Healthy BP range`, \")\", sep=\"\")) %>%\n  mutate(Stat_Hyper = paste(Count_Hypertension, \" (\", Percentage_Hypertension, \")\", sep=\"\"))%>%\n  rename(variable = age_cat) %>%\n  mutate(variable_name = \"Age\") \n\n# code adapted for SIMD\n\npercentage_SIMD_data <- BP_data_labelled2 %>%\n  group_by(SIMD, BP_cat) %>%\n  summarise(Count = n()) %>%\n  mutate(Percentage = Count / sum(Count),\n         Percentage = percent(Percentage, accuracy = 0.01)) %>%\n  pivot_wider(names_from = \"BP_cat\", values_from = c(Count, Percentage)) %>%\n  mutate(Stat_Healthy = paste(`Count_Healthy BP range`, \" (\", `Percentage_Healthy BP range`, \")\", sep=\"\")) %>%\n  mutate(Stat_Hyper = paste(Count_Hypertension, \" (\", Percentage_Hypertension, \")\", sep=\"\"))%>%\n  rename(variable = SIMD) %>%\n  mutate(variable_name = \"Scottish Index of Multiple Deprivation\")\n\n\ntable2_data <- rbind(percentage_Sex_data, percentage_UR_data, percentage_age_data, percentage_SIMD_data) %>%\n  select(variable_name, variable, Stat_Healthy, Stat_Hyper)\norder_df <- data.frame(variable = c(\"Most deprived\", \"2nd\", \"3rd\", \"4th\", \"Least deprived\"),\n  order = c(1, 2, 3, 4, 5))\n\npercentage_SIMD_data <- percentage_SIMD_data %>%\n  left_join(order_df, by = \"variable\") %>% \n  arrange(order)\n\ntable2_data <- rbind(percentage_Sex_data, percentage_UR_data, percentage_age_data, percentage_SIMD_data) %>%\n  select(variable_name, variable, Stat_Healthy, Stat_Hyper)\ngt(table2_data, groupname_col = \"variable_name\") %>%\n  tab_header(title = md(\"**Table 2**\"),\n             subtitle = md(\"Demographic statistics by blood pressure catagories\")) %>%\n  opt_align_table_header(align = \"left\") %>%\n  cols_label(variable = \" \",\n    Stat_Healthy = md(\"**Healty BP Range <br> n(%)**\"),\n    Stat_Hyper = md(\"**Hypertention <br> n(%)**\")) %>%\n  tab_options(table.border.top.color = \"white\",\n              heading.title.font.size = px(16),\n              column_labels.border.top.width = 3,\n              column_labels.border.top.color = \"black\",\n              column_labels.border.bottom.width = 3,\n              column_labels.border.bottom.color = \"black\",\n              table_body.border.bottom.color = \"black\",\n              table.border.bottom.color = \"white\",\n              table.width = pct(50),\n              table.background.color = \"white\") %>%\n  cols_align(align=\"center\") %>%\n  tab_style(style = list(cell_borders(sides = c(\"top\", \"bottom\"),\n                                      color = \"white\",\n                                      weight = px(1)),\n                         cell_text(align=\"center\"),\n                         cell_fill(color = \"white\", alpha = NULL)),\n            locations = cells_body(columns = everything(),\n                                   rows = everything()))"},{"path":"week-5---simple-linear-regression.html","id":"week-5---simple-linear-regression","chapter":"8 Week 5 - Simple Linear Regression","heading":"8 Week 5 - Simple Linear Regression","text":"week looking data behind paper titled Effects self-reported sensitivity road-traffic noise levels immune system Kim et al (2017). honest, findings paper slightly underwhelming, none--less shared data allows us apply existing R skills learn new functions directly applicable assignment.paper open access available full : Kim et al (2017). Familiarise details study take look replicating basic correlational findings.authors shared data, authors share data easy use format? course , shared PDF. Luckily , converted PDF data file CSV file can find weeks Moodle page.Thankfully data fairly tidy PDF, take much effort convert , involve mess around excel, never fun. like repeat process , steps:Excel go Data tab Get Data -> File -> PDF.Select downloaded PDF file click Import.navigation window select Select multiple items, tick either three pages three tables.click drop arrow next Load click Load .next window select Table ok.give three tabs data. matter combining data. manually copy pasting doubt smarter way .explaining partly know every come across similar data future, mainly just note inevitably forget next time. fact, book just notes help \"future \" remember code.","code":""},{"path":"week-5---simple-linear-regression.html","id":"effects-of-noise-sensitivity-and-road-traffic-noise-on-the-immune-system.","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.1 Effects of noise sensitivity and road traffic noise on the immune system.","text":"research conducted Kim colleagues 2017 set explore effects road traffic noise exposure self-reported noise sensitivity human health. study falls domain psychoneuroimmunology - scientific field investigates interplay psychological processes, nervous system, immune system.researchers specifically looked levels biomarkers related stress immune system activity potential mechanism impact.context study, several key health markers investigated:Cortisol levels: Cortisol hormone body produces stress (see last weeks lecture topic).Cortisol levels: Cortisol hormone body produces stress (see last weeks lecture topic).Natural Killer (NK) Natural Killer T (NKT) cell populations: cells key components immune system. NK cells play significant role immune response cells cancerous infected viruses. NKT cells, subset T cells properties similar NK cells, involved modulating immune responses.Natural Killer (NK) Natural Killer T (NKT) cell populations: cells key components immune system. NK cells play significant role immune response cells cancerous infected viruses. NKT cells, subset T cells properties similar NK cells, involved modulating immune responses.NK cell activity: assessed measuring levels interleukin-12 (IL-12) interferon-gamma (INF-γ), cytokines. IL-12 signaling molecule immune system gets produced body encounters intracellular pathogen. enhances ability NK cells cytotoxic T cells kill pathogens. INF-γ another cytokine crucial role immune responses, particularly viral infections cancer.NK cell activity: assessed measuring levels interleukin-12 (IL-12) interferon-gamma (INF-γ), cytokines. IL-12 signaling molecule immune system gets produced body encounters intracellular pathogen. enhances ability NK cells cytotoxic T cells kill pathogens. INF-γ another cytokine crucial role immune responses, particularly viral infections cancer.researcher obtained data markers immunological assays performed extracted blood sample participant. participant also gave following data self-report survey:Demographic factors: Age, Education level, incomeDemographic factors: Age, Education level, incomeLifestyle factors: Smoking status, Alcohol status, Exercise statusLifestyle factors: Smoking status, Alcohol status, Exercise statusSensitivity Noise: assessed 11-point visual analogue scale.Sensitivity Noise: assessed 11-point visual analogue scale.Residential noise levels (Noise_Ldn) calculated participant locating address pre-existing noise map local area taking corresponding noise level decibels.study sets test relationships noise level stress immunity biomarkers controlling demographic, lifestyle sensitivity noise variables.Today just look simple relationships come back dataset look multiple regression.always need download data, set working directory, load weeks packages, read data. using new package week (sjPlot), first time using package need install install.packages(\"sjPlot\") command.Take look dataset either visually using view() function /using summary() str() functions.single value used throughout dataset indicate missing data. need change value NA. code used last week, replace ? appropriate value run code recode missing data NAThe authors use number 999 indicate missing data.missing data dataset looks clean .","code":"\nlibrary(tidyverse)\nlibrary(sjPlot)\n\nraw_data <- read_csv(\"Kim et al data.csv\")\n\n# note you likely have the data saved under a different name to the name I have used here\nmissing_values <- ?\n\ncleaned_data <- raw_data %>%\n  mutate_all(~replace(., . %in% missing_values, NA))"},{"path":"week-5---simple-linear-regression.html","id":"replicating-kim-et-al-2017-correlational-analyses","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.1.1 Replicating Kim et al 2017 correlational analyses","text":"now, look replicate findings Figure 2 (see top page), Table 2, -text reporting (see ).may recall undergraduate research methods classes, frequentist statistical analysis, often aim use parametric tests statistical assumptions underlying tests met, tests can sensitive effects assumptions hold. However, assumptions met, non-parametric alternatives may appropriate. Note: recap topic parametric assumptions full NS5171When comes correlation analyses, parametric test commonly use Pearson correlation, commonly used non-parametric alternative Spearman's Rank correlationThis study appears performed analysis using pearson correlation (come back multiple regression couple weeks time) satisfy normality assumption used logarithmic transformation.One common method dealing non-normal data apply transformation data, logarithmic (log) transformation. can make data normally distributed, least symmetric, can help meet statistical assumptions.common variable often gets log transformation income due highly skewed nature.people earn fairly similar moderate income people earn far greater amounts bulk individuals. Graphing data (see ) see distribution skews right. Another way present data make scale logarithmic. first figure shows data second just logarithmic scale, difference point scale increases exponential manner. change makes data appear normally distributed.can achieve similar outcome performing logarithmic transformation data. graphed log income data. Notice histogram now corresponds figure log scale. transformation variable looks normal statistically normally distributed.Even though authors choose , still worth us visually inception raw data seeing looks transformation.can run histogram variables interest. case biomarkers (transformed) noise noise sensitivity variables (transform). already know (able work ) run simple histogram now, try using code.just run histogram code 7 times, changing variable name time. However, can often look messy script, way tidy things may want run together. , first select() key variables. can use pivot_longer function, followed including facet_wrap line within ggplot code create single image plots.Pivoting data refers reshaping dataset, transition 'wide' format 'long' format, vice versa.'wide' format, row corresponds single observation, variable column. , current dataset can said 'wide' format.'long' format, row still represents single observation, variables examining compiled one column. Additional columns provide distinct information observation. example, might one row measurement taken, one column specifying type measurement another giving measurement value .makes sense look data. example :dataset wide format:example dataset long format (pivoting)take look data pivoting see scores one variable named score. Running histogram code facet_wrap gives histograms .think? variables skewed?going go two highly skewed (INFgammer & NKT_cells) one close skewed (IL12). However, without checking statistically (show check later course) hard know sure.Anyway, follow authors perform log transformation biomarkers.Now can log transformation biomarkers run histograms .Adapt piviot facet_wrap code rerun histograms log transformed data. end range histograms look something like :","code":"\ncleaned_data %>%\n  ggplot(aes(x = Cortisol)) +\n  geom_histogram()\n\n# or this if you want to tidy it up:\n\ncleaned_data %>%\n  ggplot(aes(x = Cortisol)) +\n  geom_histogram(fill = \"darkgreen\", color = \"black\") +\n  ggtitle(\"Histogram of Cortisol Levels\") +\n  xlab(\"Cortisol Levels\") +\n  ylab(\"Frequency\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\nhistogram_data <- cleaned_data %>%\n  select(Cortisol, \n         NK_cells, \n         NKT_cells, \n         IL12, \n         INFgamma, \n         Noise_Ldn, \n         Noise_sensitivity) %>%\n  pivot_longer(cols = 1:7, names_to = \"variables\", values_to = \"score\")\nhistogram_data %>%\n  group_by(variables)%>%\n  ggplot(aes(x = score)) +\n  geom_histogram(fill = \"darkgreen\", color = \"black\") +\n  facet_wrap(~variables, scale = \"free\")\ncleaned_data_log <- cleaned_data %>%\n  mutate(Cortisol_log = log(Cortisol),\n         NK_cells_log = log(NK_cells),\n         NKT_cells_log = log(NKT_cells),\n         IL12_log = log(IL12),\n         INFgamma_log = log(INFgamma))"},{"path":"week-5---simple-linear-regression.html","id":"one-more-annoying-thing-before-we-can-actually-analyse-the-data","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.1.2 One more annoying thing before we can actually analyse the data","text":"One variables going give us issues next section due log transformation. run summary dataset, just take look new data object containing log variables, see data points NKT_cell_log variable listed -Inf. due us trying take log 0, equals infinity.sure Kim et al addressed issue, however, going address converting -Inf values 0's. done adding extra mutate function log transformation expression. line use ifelse say value NKT_cells_log infinite replace 0, else replace value .","code":"\ncleaned_data_log <- cleaned_data %>%\n  mutate(Cortisol_log = log(Cortisol),\n         NK_cells_log = log(NK_cells),\n         NKT_cells_log = log(NKT_cells),\n         IL12_log = log(IL12),\n         INFgamma_log = log(INFgamma)) %>%\n  mutate(NKT_cells_log = ifelse(is.infinite(NKT_cells_log), 0, NKT_cells_log))\n\n# take a look just to check\n\ncleaned_data_log %>%\n  ggplot(aes(x = NKT_cells_log)) +\n  geom_histogram()"},{"path":"week-5---simple-linear-regression.html","id":"correlation-matrix","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.2 Correlation matrix","text":"data wrangling finally stage can start replicating authors primary analysis.single correlation can run following code:example \"base R\" coding (.e. R functionality involve tidyverse package). Frustratingly, cor.test function compatible pipes (%>%) tidyverse (even base R pipes |>) old fashioned way. cleaned_data_log$Noise_Ldn means : \"Take Noise_Ldn variable et cleaned_data_log data object\".worth knowing type notation, point likely run across blogs tutorial videos use code.running line code see following appear console:important information us extract output p-value cor value, indicates r, correlation coefficient pearsons correlation. case r value 0.233 p-value 0.002. APA style report finding following: significant positive correlation Noise level IL-12 levels, r(170) = .233, p < .01Therefore, sucessfully replicated finding? YesNoWe run correlations present Table 2 separately, build table.valid method analysis. However, considering 7 variables, combinations quickly increase. require 21 distinct lines code subsequent task extracting outcomes. streamline process, can use sjPlot package generate correlation matrix.first expresion code (loading package) creates new data object containing relevant data matrix.first expresion code (loading package) creates new data object containing relevant data matrix.second experssion assembles correlation table using chosen data. incorporated additional arguments code functionality. view comprehensive list available arguments table, run ?tab_corr. Note: resulting table, generated HTML format, display viewer tab rather plot tab.second experssion assembles correlation table using chosen data. incorporated additional arguments code functionality. view comprehensive list available arguments table, run ?tab_corr. Note: resulting table, generated HTML format, display viewer tab rather plot tab.final expression visualises data colour-coded grid. find format intuitive identifying high correlations large datasets. Similarly, running ?sjp.corr gives full list available arguments type plot.final expression visualises data colour-coded grid. find format intuitive identifying high correlations large datasets. Similarly, running ?sjp.corr gives full list available arguments type plot.successful replicating correlational findings Kim et al (2017)?Yes, seems . primary significant findings largely line original study, though minor variances correlation coefficients. can tell, disparities appear influenced Noise Sensitivity NKT cells variables. variations NKT cells variable understandable given variable -inf values. possible original authors addressed differently . Noise Sensitivity variable, somewhat stumped. values closely aligned identical. figure , please get touch let know missed .","code":"\ncor.test(x = cleaned_data_log$Noise_Ldn, y = cleaned_data_log$IL12_log)\n# Pearson's product-moment correlation\n\n# data:  cleaned_data_log$Noise_Ldn and cleaned_data_log$IL12_log\n# t = 3.1267, df = 170, p-value = 0.00208\n# alternative hypothesis: true correlation is not equal to 0\n# 95 percent confidence interval:\n#  0.08658474 0.36992397\n# sample estimates:\n#       cor \n# 0.2331978 \nlibrary(sjPlot)\n\ncorr_matrix_data <- cleaned_data_log %>%\n  select(Noise_Ldn, Noise_sensitivity, Cortisol_log, NK_cells_log, NKT_cells_log, IL12_log, INFgamma_log)\n\ntab_corr(data = corr_matrix_data,\n         triangle = \"lower\",\n         corr.method = \"pearson\",\n         show.p = TRUE,\n         title = \"Table 2. Correlation among noise levels, noise sensitivity and immune response.\",\n         var.labels = c(\"Ldn\", \"Noise sensitivity\", \"Cortisol\", \"NK Cells\", \"NKT cells\", \"IL-12\", \"INFgamma\"))\n\nsjp.corr(data = corr_matrix_data,\n         corr.method = \"pearson\",\n         show.legend = TRUE,\n         sort.corr = FALSE,\n         title = \"Figure 1. Correlation plot of variables\",\n         axis.labels = c(\"Ldn\", \"Noise sensitivity\", \"Cortisol\", \"NK Cells\", \"NKT cells\", \"IL-12\", \"INFgamma\"))"},{"path":"week-5---simple-linear-regression.html","id":"simple-regression-plots.","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.3 Simple Regression Plots.","text":"Lastly, can now replicate plots Figure 2. plots involve simple scatter plot addition regression line, regression formula, R-Squared value. go detail aspects NS7151, however, quick overview concepts.Regression line: Adding regression line helps capture trend data. line represents 'best fit' scatter points, indicating overall relationship variables.Regression formula: regression formula mathematical equation regression line, typically form y = mx + b. m denotes slope (effect x y), b y-intercept (y value x zero).R-Squared value: R-squared value, ranging 0 1, shows well regression line fits data. high R-squared means significant portion variation dependent variable can explained independent variable(s).code runs linear regression, modelling relationship Cortisol Noise Levels. view model run summary() newly created model. results model outputted console.can see R-Squared matches plot figure 2 also tells us relationship significant (p=0.399).Pr(>|t|) output stands \"p-value t-statistic\".t-statistic measures size difference relative variation sample data. larger absolute value generally means likely meaningful difference.p-value (Pr(>|t|)) probability observe large absolute t-value null hypothesis (.e., effect relationship) true. Smaller p-values suggest null hypothesis less likely, effect relationship observed likely real due random chance.case looking p-value Noise_Ldn predictor model. greater 0.05 (threshold often choose psychology statistical significance). Therefore, relationship significant (also found correlation matrix).figures need extract bits information model. first line code takes just r-squared value stores value r-squared. next line coefficients model (m b equation line).equation expression takes coefficients turns string contains equation line (y=0.0025*x + 2.4). last line r-squared values.Now can create plot. similar plots created, however, time used annotate function add text labels. play around code see can figure arguments within code .","code":"\nmodel_Cort_Ldn <- lm(Cortisol_log ~ Noise_Ldn, data = cleaned_data_log)\n\nsummary(model_Cort_Ldn)\nr_squared <- summary(model_Cort_Ldn)$r.squared\ncoefficients <- coef(model_Cort_Ldn)\n\nequation <- paste0(\"y = \",\n                   round(coefficients[2], digits = 4),\n                   \" * x + \",\n                   round(coefficients[1], digits = 2))\n\nr_squared <- paste0(\"R\\u00B2 = \", round(summary(model_Cort_Ldn)$r.squared, 3))\n\n# \\u00B2 is the code for making text superscript, i.e. turning the 2 into squared.\ncleaned_data_log %>%\n  ggplot(aes(x = Noise_Ldn, y = Cortisol_log)) +\n  geom_point(shape = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\", linetype = \"dashed\") +\n  scale_x_continuous(limits = c(30, 100)) +\n  scale_y_continuous(limits = c(1.5, 3.5)) +\n  xlab(label = \"Noise Level\") +\n  ylab(label = \"Cortisol\") +\n  ggtitle(\"Figure 2A: A plot to show the relationship between Noise and Cortisol levels\") +\n  annotate(\"text\", x = 88, y = 2.8, label = equation) +\n  annotate(\"text\", x = 95, y = 3.5, label = r_squared)"},{"path":"week-5---simple-linear-regression.html","id":"video-walkthrough-4","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.4 Video walkthrough","text":"","code":""},{"path":"week-5---simple-linear-regression.html","id":"test-yourself-exercise-3","chapter":"8 Week 5 - Simple Linear Regression","heading":"8.5 Test yourself exercise","text":"Create plots significant findings Figure 2. Try get resemble original closely can.something wild study, perhaps noticed, Men excluded analysis. authors argued due Men tending \"activity environments outside residence target area\" \"influence [] sensitivity environmental noise around residence\".bit red flag . Especially seeing blood samples still collected individuals (67 total).make things worse, :move now, anyone time, please rerun analysis two participants filtered . interesting see makes difference.book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":"\nraw_data %>%\n  select(Sex)%>%\n  group_by(Sex)%>%\n  summarise(count = n())"},{"path":"week-6---catch-up-week.html","id":"week-6---catch-up-week","chapter":"9 Week 6 - Catch up week","heading":"9 Week 6 - Catch up week","text":"Well done! made halfway point semester. week Psych Lab looking lab based biometric data collection methods.seemed like good point semester give chance catch exercises previous weeks point towards resources may find use:","code":""},{"path":"week-6---catch-up-week.html","id":"psyteachr","chapter":"9 Week 6 - Catch up week","heading":"9.1 PsyTeachR","text":"first recommendation PsyTeachR. resource University Glasgow use teach undergraduate postgraduate psychology students R. resource used first learning code (around 2 years ago) inspiration writing handbook. Data Skills module good place start.","code":""},{"path":"week-6---catch-up-week.html","id":"r-for-data-science","chapter":"9 Week 6 - Catch up week","heading":"9.2 R for data science","text":"R data science Wickham, Çetinkaya-Rundel & Grolemund way code Tidyverse, written maintain code.Lots depth , great want gain deeper understanding rather just rely editing code give .Also code one way, task another way, way! likely () right.","code":""},{"path":"week-6---catch-up-week.html","id":"tidytuesday","chapter":"9 Week 6 - Catch up week","heading":"9.3 TidyTuesday","text":"TidyTuesday online community hobbyists professionals work data. week release new dataset community anlyse visualise data share online rest community.Recent datasets include:UFO SightingsLondon Marathon dataHollywood relationship age gapsScroll links give description dataset info read dataset R.Search #TidyTuesday twitter elsewhere get idea community creates. Often also share code.","code":""},{"path":"week-6---catch-up-week.html","id":"youtube-channels-of-note","chapter":"9 Week 6 - Catch up week","heading":"9.4 YouTube channels of note","text":"YouTube indispensable first learning R. first video saw topic: R programming one hour - crash course beginners.channels recommendations:R Programming 101Equitable EquationsPositThis book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":""},{"path":"week-7---multiple-regression.html","id":"week-7---multiple-regression","chapter":"10 Week 7 - Multiple Regression","heading":"10 Week 7 - Multiple Regression","text":"aim week get used constructing multiple regression models running statistical assumption checks R. point semester covered theory regression analysis NS7151 using JASP (click recap). know , session likely got frustrated limitations JASP program, especially around regression analysis. , week opportunity introduce extra functionality R make clear choice running regression analysis.Running multiple regression R actually easy, couple lines simple code. also add data wrangling give realistic experience real world data analysis might look like.week instead replicating findings published paper using open access large survey similar assignment data. time 2011 Health Survey England. User Guide data raw data can found weeks folder Moodle.","code":""},{"path":"week-7---multiple-regression.html","id":"required-packages","chapter":"10 Week 7 - Multiple Regression","heading":"10.1 Required Packages","text":"packages need week. broom package likely new need install first.","code":"\nlibrary(tidyverse)\nlibrary(sjPlot) # for the correlation plots and presenting the regression model in a table\nlibrary(broom) # makes it easier to work with model data"},{"path":"week-7---multiple-regression.html","id":"importing-and-cleaning-the-data","chapter":"10 Week 7 - Multiple Regression","heading":"10.2 Importing and cleaning the data","text":"data file folder set working directory loaded packages, following code import raw data R.exercise going try predict Body Mass Index (BMI) using age, alcohol consumption, fruits & veg consumption, smoking behaviour.Rather work whole dataset, often find easier select just variables want use analysis. case want variables related BMI, alcohol, age, fruits & veg, smoking.See can find variables might able use analysis. need cross reference variable names dataset topics User Guide. possible select continuous variables.following code selects chosen variables (replace ? chosen variables). code goes deal missing data filters data participants complete data variables.hit error running code? See can figure see can get point variables need analysis.User Guide says one variables dataset, .Can calculate another means?BMI missing, weight height. formula calculating BMI:\\[\n\\text{BMI} = \\frac{\\text{Weight kg}}{(\\text{Height m})^2}\n\\]likely ways solve issue, :last bit cleaning dataset convert smoking variable binary variable. make interpretation model great deal easier stage. According User Guide coding cigst1 follows:1 = Never smoked cigarettes all2 = Used smoke cigarettes occasionally3 = Used smoke cigarettes regularly4 = Currently cigarette smokerI suggest recoding variable first two categories low usage categories 3 4 high usage.Also, can create categorical variable derived newly constructed BMI variable, based different levels BMI.Find category boundaries BMI literature replace ? code .","code":"\nraw_data <- read_csv(\"hse2011.csv\")data_cleaned <- raw_data %>%\n  select(?) %>%\n  mutate(across(everything(), ~ replace(., . %in% c(-1, -8, -9, -10), NA))) %>%\n  filter(across(everything(), ~ !is.na(.)))\ndata_cleaned <- raw_data %>%\n  select(htval, wtval, totalwu, porfv, Age, cigst1) %>%\n  mutate(across(everything(), ~ replace(., . %in% c(-1, -8, -9, -10), NA))) %>%\n  filter(across(everything(), ~ !is.na(.)))\n\ndata_cleaned <- data_cleaned %>%\n  mutate(height_m = htval/100) %>%  \n  mutate(bmi = wtval/(height_m^2))data_cleaned <- data_cleaned %>%\n  mutate(cig_binary = recode(cigst1, \n                         \"1\" = \"Low\",\n                         \"2\" = \"Low\",\n                         \"3\" = \"High\",\n                         \"4\" = \"High\")) %>%\n    mutate(bmi_cat = case_when(\n      bmi < ? ~ \"?\",\n      bmi >= ? & bmi < ? ~ \"?\",\n      bmi >= ? & bmi < ? ~ \"?\",\n      bmi >= ? & bmi < ? ~\"?\"\n      bmi >= ? ~ \"?\"))"},{"path":"week-7---multiple-regression.html","id":"visualising-our-data","chapter":"10 Week 7 - Multiple Regression","heading":"10.3 Visualising our data","text":"usual, always good idea visual inspection data. start DV. two ways can think visualising data. First histogramI decided just use three BMI categories demonstrate salient weight groups. added manually coloured line coloured text, placed empty part figure. usual probably efficient way way makes sense , also makes easier adapt need code later date.Another way visualise variable way visualised blood pressure data week 4. See can adapt code make following figure (something close ).figure certainly looks pretty, perhaps overly informative.also check predictor variables well. continuous variables can create plots together just week 5 piviot facet_wrap.can course run three separate histograms find easier.looks like alcohol fruit & veg variables right skewed. necessary violation statistical assumption regression models, likely outliers. consider removing statistical assumptions model violated.","code":"\ndata_cleaned %>%\n  ggplot(aes(x = bmi)) +\n  geom_histogram(bins = 30, alpha = 0.7, fill = \"darkgreen\", colour = \"black\") +\n  geom_vline(aes(xintercept = 18.5), color = \"blue\", \n             linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = 30), color = \"orange\", \n             linetype = \"dashed\", size = 1) +\n  geom_vline(aes(xintercept = 40), color = \"red\", \n             linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = 50, y = 900, \n           label = \"Underweight\", hjust = 0, vjust = 1, color = \"blue\") +\n  annotate(\"text\", x = 50, y = 800, \n           label = \"Obese\", hjust = 0, vjust = 1, color = \"orange\") +\n  annotate(\"text\", x = 50, y = 700, \n           label = \"Severely obese\", hjust = 0, vjust = 1, color = \"Red\") +\n  labs(title = \"Figure 1: Distribution of BMI in the Sample\",\n       x = \"Body Mass Index (BMI)\",\n       y = \"Frequency\") +\n  theme_minimal()\ndata_cleaned %>%\n  select(totalwu, Age, porfv)%>% \n  rename(Alcohol = totalwu,\n         `Fruit&Veg` = porfv) %>%\n  pivot_longer(cols = c(Alcohol, Age, `Fruit&Veg`),\n               names_to = \"Variable\",\n               values_to = \"Value\")%>%\n  ggplot(aes(x= Value)) +\n  geom_histogram(fill = \"darkred\", colour = \"black\")+\n  facet_wrap(~Variable, scale = \"free\") +\n  labs(title = \"Figure 3: Histograms of continuious predictor variables\",\n       y = \"Frequency\")"},{"path":"week-7---multiple-regression.html","id":"fitting-the-multiple-regression-model","chapter":"10 Week 7 - Multiple Regression","heading":"10.4 Fitting the multiple regression model","text":"mentioned top, fitting regression model R simple. code model first model predicts BMI using alcohol consumption, age, portions fruit veg smoking behaviour:uses lm function context stands linear model. add bmi variable dependent variable, variable ~ predictor variables. important include data = argument , sadly, pipe data often . Also, needs go end expression rather beginning (aspect often trips ).lm function creates list object (instead dataframe tibble often used seeing). easy read (click model object just created see ). instead, get results model can run following print results console:, broom package loaded can add tidy function model expression store model tibble.ways presenting model course ugly communicating findings. sjPlots package best package found putting regression findings APA style tables. Make sure package loaded run following get results nice table, fit exporting.functions arguments can use improve table somewhat. code final table.","code":"\nmodel <- lm(bmi ~ totalwu + Age + porfv + cig_binary, data = data_cleaned)\nsummary(model)\nlibrary(broom)\nmodel_tibble <- lm(bmi ~ totalwu + Age + porfv + cig_binary, data = data_cleaned) %>%\n  tidy()\nlibrary(sjPlot)\n\ntab_model(model)\ntab_model(model,\n          pred.labels = c(\"(Intercept)\", \n                          \"Alcohol\",\n                          \"Age\",\n                          \"Portions of Fruit & Veg\",\n                          \"Smoker(ref=high)\"),\n          dv.labels = c(\"BMI\"),\n          string.est = \"B\",\n          title = \"Table 1. Predictors of BMI (Model 1)\")"},{"path":"week-7---multiple-regression.html","id":"how-to-read-a-regression-model","chapter":"10 Week 7 - Multiple Regression","heading":"10.5 How to read a regression model","text":"Make sure check back NS7151 content full explanation interpret regression analysis, however, main takeaways:R-Squared Adjusted R-Squared:\n\\(R^2\\) value model 0.031, indicating 3.1% variance BMI explained predictors. essential look adjusted \\(R^2\\) multiple regression, penalises model including non-useful predictors.Estimates (Coefficients):Continuous Variables - coefficient Age 0.051. means additional year life, BMI expected increase 0.051 points, assuming variables held constant.Categorical Variables - coefficient cig_binary -0.22. 'low' cigarette usage associated 0.22-point decrease BMI compared 'high' usage. interpretation can also flipped given negative sign.Just safe side might make sense us change reference category variable, rather remembering flip sign write . amendment changes interpretation model fit. can following code:Confidence Intervals:\n95% Confidence Interval (CI) gives us range can 95% confident population parameter lies. Narrower CIs indicate reliable estimates. CI coefficient include zero, generally considered statistically significant.P-Value:\np-value indicates probability observed effect occurred chance actually effect. p-value less 0.05 generally considered statistically significant, although threshold can vary.Standard Error:\nStandard error measures amount variability estimate coefficient. Lower standard error values imply precise estimates.","code":"\ndata_cleaned$cig_binary <- as.factor(data_cleaned$cig_binary)\n\ndata_cleaned$cig_binary <- relevel(data_cleaned$cig_binary, ref = \"Low\")\n\nmodel <- lm(bmi ~ totalwu + Age + porfv + cig_binary, data = data_cleaned)\n\nsummary(model)"},{"path":"week-7---multiple-regression.html","id":"regression-equation","chapter":"10 Week 7 - Multiple Regression","heading":"10.5.1 Regression Equation","text":"summarise linear model fitted predict bmi, regression equation follows:\\[\n\\text{BMI} = 25.29 + 0.05 \\times \\text{Age} - 0.05 \\times \\text{PorFV} + \\epsilon\n\\]","code":""},{"path":"week-7---multiple-regression.html","id":"statistical-assumption-checks","chapter":"10 Week 7 - Multiple Regression","heading":"10.6 Statistical assumption checks","text":"wanted explain modelling aspect prior section statistical assumption checks (likely main reason ), reality assumption checks either take place prior , , model fitting process. assumptions check example followed:- Linearity: Predictor variables linear relationship dependent variable.- Multicollinearity: Predictor variables share particularly strong relationships .- Normality residuals: residuals—difference observed predicted values—approximately normally distributed.- Homoscedasticity: data homoscedastic, meaning variance errors remain constant across levels independent variable(s).assumptions exist, sufficient level study.","code":""},{"path":"week-7---multiple-regression.html","id":"linear-relationship-with-the-dv","chapter":"10 Week 7 - Multiple Regression","heading":"10.6.1 Linear relationship with the DV","text":"check see linear relationship DV can use pivot_longer trick run three scatter plots simultaneously three continuous variables model.Take adapt histogram code try make image .Age evidence nice liner trend BMI. Alcohol Fruit&Veg hard tell. perhaps argument check later decide remove outliers.","code":""},{"path":"week-7---multiple-regression.html","id":"check-for-multicollinearity","chapter":"10 Week 7 - Multiple Regression","heading":"10.6.2 Check for Multicollinearity","text":"Next, need check relationships predictor variables. looking correlation coefficient relationship around r = 0.7.Adapt code week 5 make following correlation matrix correlation plot.looks good . greatest magnitude correlation coefficient predictor variables Age Portions fruit & Veg r = 0.086. Far multicollinearity cut 0.7. Next week show another check (VIF) intuitive use categorical variables.","code":""},{"path":"week-7---multiple-regression.html","id":"check-the-residuals-normality","chapter":"10 Week 7 - Multiple Regression","heading":"10.6.3 Check the residuals (normality)","text":"normality check regression normality continuous variables residuals model. reminder residuals see content shared NS7151(Link).Unlike using JASP, R can extract residuals fitted values model. can use manually create assumption check visualisations. code extracts values model created.residuals extracted model just matter running histogram. image run added normal distribution curve compare distribution , bar along bottom show harder spot data points .adding aes(y = ..density.. geom_histogram stat_function expression can compare data perfect normal distribution. geom_rug handy addition allows us see data points plots dealing lot data.","code":"\nresiduals_data <- tibble(model_residuals = residuals(model),\n                          model_fitted_values = fitted(model))\nresiduals_data %>%\n  ggplot(aes(x = model_residuals)) +\n  geom_histogram(aes(y = ..density..), bins = 50, colour = \"black\", fill = \"darkblue\") + \n  stat_function(fun = dnorm, \n                args = list(mean = mean(residuals_data$model_residuals, na.rm = TRUE),\n                                         sd = sd(residuals_data$model_residuals, na.rm = TRUE)), \n                colour = \"red\", size = 1.5, alpha = 0.7) +\n  geom_rug() +\n  labs(\n    title = \"Figure 5. Histogram of Residuals (model 1)\",\n    x = \"Residuals\",\n    y = \"Density\"\n  ) +\n  theme_minimal()"},{"path":"week-7---multiple-regression.html","id":"check-for-homoscedasticity","chapter":"10 Week 7 - Multiple Regression","heading":"10.6.4 Check for homoscedasticity","text":"Homoscedasticity implies variance error terms (residuals) constant across independent variables. words, \"spread\" residuals remain consistent fitted value changes. Violations assumption, known heteroscedasticity, can lead inefficient parameter estimates unreliable significance tests.visually inspect homoscedasticity, often use plot residuals fitted values (values model predicts). \"well-behaved\" plot show random scattering points, indicate heteroscedasticity.smooth fitted line best fit (loess curve) flat line zero.R code generates plot:hmmm, looks like issue . pain, likely caused outliers probably worth conducting sensitivity analysis.","code":"\nresiduals_data %>%\n  ggplot(aes(x = model_fitted_values, y = model_residuals)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"loess\", se = FALSE, colour = \"red\") +\n  labs(\n    title = \"Residuals vs Fitted Values\",\n    x = \"Fitted Values\",\n    y = \"Residuals\"\n  ) +\n  theme_minimal()"},{"path":"week-7---multiple-regression.html","id":"sensitivity-analysis","chapter":"10 Week 7 - Multiple Regression","heading":"10.7 Sensitivity analysis","text":"Sensitivity analysis technique employed assess robust model's results changes data assumptions. context regression modelling, often involves running multiple versions model see certain modifications affect outcomes. current analysis run model outliers included, now lets run outliers removed.following code calculates outliers based upper lower quartile + - 1.5 time interquartile range. explanation technique (Link), also used briefly labelling outliers boxplot week 2.","code":"\nsensitivity_model_data <- data_cleaned %>%\n  mutate(iqr_totalwu = IQR(totalwu, na.rm = TRUE),\n         iqr_porfv = IQR(porfv, na.rm = TRUE),\n         upper_totalwu = quantile(totalwu, 0.75, na.rm = TRUE) + 1.5 * iqr_totalwu,\n         lower_totalwu = quantile(totalwu, 0.25, na.rm = TRUE) - 1.5 * iqr_totalwu,\n         upper_porfv = quantile(porfv, 0.75, na.rm = TRUE) + 1.5 * iqr_porfv,\n         lower_porfv = quantile(porfv, 0.25, na.rm = TRUE) - 1.5 * iqr_porfv) %>%\n  filter(totalwu < upper_totalwu & totalwu > lower_totalwu,\n         porfv < upper_porfv & porfv > lower_porfv)%>%\n  select(totalwu, Age, porfv, cig_binary, bmi)"},{"path":"week-7---multiple-regression.html","id":"test-yourself-exercise-4","chapter":"10 Week 7 - Multiple Regression","heading":"10.8 Test yourself Exercise","text":"Run model assumption checks sensitivity_model_data. name model sensitivity_model code allow combine models together table. forget also change reference category smoking variable (least keep consistant across models).","code":"\ntab_model(model, sensitivity_model,\n          pred.labels = c(\"(Intercept)\", \n                          \"Alcohol\",\n                          \"Age\",\n                          \"Portions of Fruit & Veg\",\n                          \"Smoker(ref=Low)\"),\n          dv.labels = c(\"Model\", \"Sensitivity model\"),\n          string.est = \"B\",\n          title = \"Table 3. Predictors of BMI (Model & Sensitivity model)\")"},{"path":"week-7---multiple-regression.html","id":"what-does-the-sensitivity-analysis-tell-us","chapter":"10 Week 7 - Multiple Regression","heading":"10.8.1 What does the sensitivity analysis tell us?","text":"","code":""},{"path":"week-7---multiple-regression.html","id":"sensitivity-assumption-checks","chapter":"10 Week 7 - Multiple Regression","heading":"10.8.1.1 Sensitivity assumption checks","text":"assumption checks sensitivity analysis data, might noticed slight difference homoscedasticity plot, data still violates assumption (opinion).ran histograms seen alcohol variable still right skewed. point analysis took log alcohol variable, see solves issue. anyway -turn make harder interpret findings perhaps two models might best can data.continue research, also want read alcohol research literature see often use variable. often added complexity asking people alcohol consumption. 0 alcohol intake can explained respondent 18, non-drinker adult, ex-alcoholic now abstains, likely differ greatly related health statuses.Either way important report violation present models reader can make interpretation.","code":""},{"path":"week-7---multiple-regression.html","id":"sensitivity-model-results","chapter":"10 Week 7 - Multiple Regression","heading":"10.8.1.2 Sensitivity model results","text":"results hopefully end :Alcohol: every one-point increase alcohol variable, BMI decreases 0.02 points.Age: every one-year increase age BMI increases 0.05 pointsFruit & Veg: every one-point increase fruit & veg variable, BMI decreases -0.08 pointsSmoking: high smoker (compared low) associated 0.082 point increase BMIFrom comparison hopefully can see fickle p-values can . Just small change data findings change completely. important look effect sizes decide meaningful. Personally, seems like Age meaningful predictor BMI model. Just see happens \\(R^2\\) value run model without age variable.surprised lack influence variables, worth remembering just complicated understanding predictors weight can .","code":""},{"path":"week-7---multiple-regression.html","id":"video-walkthrough-5","chapter":"10 Week 7 - Multiple Regression","heading":"10.9 Video Walkthrough","text":"book work progress. feedback spot mistakes please enter feedback survey quoting week comment referring . Thank ! :-)","code":""},{"path":"week-8---logistic-regression.html","id":"week-8---logistic-regression","chapter":"11 Week 8 - Logistic regression","heading":"11 Week 8 - Logistic regression","text":"week replicating analysis related recent paper Jamil et al (2023) titled Socio-demographic determinants Monkeypox virus preventive behaviour: cross-sectional study Pakistan. study uses frequent framing Public Health; surveying knowledge, attitudes perceptions (KAP).Researcher often uses KAP studies identify knowledge gaps, misconceptions attitudes may influence preventative practices. Monkeypox declared public health emergency international concern mid 2022 kind study understandable first step public health response.authors conduct series logistic regressions shared data. Making good candidate us practice logistic regression prior potentially using analysis assignment.weeks code replicates Table 1 last three columns Table 5 paper.","code":""},{"path":"week-8---logistic-regression.html","id":"the-data","chapter":"11 Week 8 - Logistic regression","heading":"11.1 The Data","text":"authors shared data SPSS file. Fiddling around SPSS file get format use analysis useful skill one related assignment. , instead, given somewhat cleaned version dataset .csv file.Download file Jamil et al 2023 cleaned.csv Moodle. Set working directory load data RStudio.Take look data file take look Table 1 Jamil et al. See can identify variables need recreate table.looking dataset, age variable need converted categorical variable. See can without looking code blue box . need use case_when function. given example use function previously. Check paper paper categories authors used make sure call variable age_cat rest code chapter works.Run following code get count age groups. may need replace age_cat variable name mutated variable without code.numbers match Table 1 paper? , look like .mean recoded variable incorrectly? , think either.different numbers ?Well, lot head scratching, found 21-30 category actually 21-29 31-40 category actually 29-39. code creates calculation adds dataset.strange way code variable. wonder prove important difference later analysis.","code":"\njamil2023 <- read_csv(\"Jamil et al 2023 cleaned.csv\") \njamil2023 <- jamil2023 %>%\n  mutate(age_cat = case_when(\n    age <= 20 ~ \"less than 20\",\n    age > 20 & age < 31 ~ \"21 - 30\",\n    age >= 31 & age <= 40 ~ \"31 - 40\",\n    age > 40 ~ \"40+\",\n    TRUE ~ \"Other\"))\njamil2023 %>%\n  group_by(age_cat) %>%\n  summarise(n = n())\njamil2023 <- jamil2023 %>%\n  mutate(age_cat_author = case_when(\n    age <= 20 ~ \"less than 20\",\n    age > 20 & age < 29 ~ \"21 - 30\",\n    age >= 29 & age < 40 ~ \"31 - 40\",\n    age >= 40 ~ \"40+\",\n    TRUE ~ \"Other\"))\n\njamil2023 %>%\n  group_by(age_cat_author) %>%\n  summarise(n = n())"},{"path":"week-8---logistic-regression.html","id":"data-wrangling-1","chapter":"11 Week 8 - Logistic regression","heading":"11.2 Data wrangling","text":"following code chunk gets data right form table later regression one go.code:\n1. Renames variables look appropriate tables.\n2. Changes data type variable factor (rather just character data)\n3. Changes order variable needs order changed.\n4. Dummy codes dependent variables ready logistic regression.Dummy coding used regression analysis transform categorical variable binary variable (0s 1s). necessary regression models require numerical input. dummy coding, one category chosen reference group assigned value 0. categories compared reference group.case, want take continuous knowledge variable use model \"Good Knowledge\" given value 1 \"Poor Knowledge\" given value 0.Remember, see big chunk code like like explained , excellent way use AI. Chat GPT says code: Link","code":"\nanalysis_data <- jamil2023 %>%\n  mutate(Gender = factor(gender, \n                         levels = c(\"Male\", \"Female\")),\n         Age = factor(age_cat_author,\n                      levels = c(\"less than 20\", \"21 - 30\", \"31 - 40\", \"40+\")),\n         `Marital status` = factor(marital_status,\n                                   levels = c(\"Married\", \"Unmarried\")),\n         Residence = factor(residence,\n                            levels = c(\"Urban\", \"Rural\")),\n         Education = factor(education,\n                            levels = c(\"Primary up to Matriculation\",\n                                       \"Intermediate\",\n                                       \"Graduation\",\n                                       \"Post-graduation\")),\n         `Monthly income in PKR` = factor(income,\n                                          levels = c(\"<50,000\",\n                                                     \"50,000 - 100,000\",\n                                                     \">100,000\"))) %>%\n  mutate(knowledge_dummy = recode(knowledge_cat,\n                                  \"Poor knowledge\" = 0,\n                                  \"Good knowledge\" = 1),\n         attitude_dummy = recode(attitude_cat,\n                                   \"Negative attitude\" = 0,\n                                   \"Positive attitude\" = 1),\n         practice_dummy = recode(practice_cat,\n                                   \"Not positive practice\" = 0,\n                                   \"Positive practice\" = 1))"},{"path":"week-8---logistic-regression.html","id":"recreating-table-1","chapter":"11 Week 8 - Logistic regression","heading":"11.3 Recreating Table 1","text":"gtsummary package really useful creating descriptive statistics table Table 1 Jamil et al (2023).First, make sure package installed loaded need select variables need summaries use tbl_summary() function.last line create table Viewer window. want see table full glory, click \"Show new window\" button open table web browser.quite authors version, can tidy little playing around arguments converting table compatible gt package. video explaining gt package possible build .save web browser version open Microsoft Word can also edit table. Really useful adding final last touches.","code":"\nlibrary(gtsummary)\n\ntable1_data <- analysis_data %>%\n  select(Gender, Age, `Marital status`, Residence, Education, `Monthly income in PKR`)\n\ntbl_summary(table1_data)\nlibrary(gt)\n\ntable1_raw <- tbl_summary(table1_data) %>%\n  as_gt()\n\ntable1_raw %>%\n  tab_header(\"Table 1. Study sample socio-demographic characteristics (N = 1041)\") %>%\n  tab_style(style = cell_text(align = \"left\", weight = \"bold\"),\n            locations = cells_title(groups = \"title\")) %>%\n  cols_label(label = \"Variables\",\n             stat_0 = \"Frequency\") %>%\n  tab_footnote(\"PKR: Pakistani Rupee\")"},{"path":"week-8---logistic-regression.html","id":"running-and-interpreting-a-logistic-regression","chapter":"11 Week 8 - Logistic regression","heading":"11.4 Running and interpreting a logistic regression","text":"table 5 6 author runs series univariate logistic regression (.e. simple regression just one variable) multivariate logistic regression univariate analysis p-value less 0.25. Normally cut sort procedure 0.1. However just left two variables model can see chose pick 0.25.important step conducting logistic regression carefully consider category like categories compared .following code tells data categories want reference category performs logistic regression.tab_model function sjPlot package likely best easiest way present findings logistic regression good looking table.Run code ref = \"Graduation\" see changes reference category. underlying results still now group comparison Graduation group opposed Intermediate group.run full multivariate model need build code reference category set model contains relevant variables.Remember earlier coded age variable found authors misscoded initial attempt. code sets reference catagory variable calculated (called age_cat) see can rerun mode variable. variables significant authors model significant age variable coded correctly.","code":"\nanalysis_data <- analysis_data %>%\n  mutate(Education = relevel(as.factor(Education), ref = \"Intermediate\"))\n\nunivariate_ed <- glm(knowledge_dummy ~ Education, data = analysis_data, family = binomial)\n\ntab_model(univariate_ed,\n          show.reflvl = TRUE,\n          show.intercept = FALSE)\nanalysis_data <- analysis_data %>%\n  mutate(Gender = relevel(as.factor(Gender), ref = \"Female\"),\n    Age = relevel(as.factor(Age), ref = \"40+\"),\n    age_cat = relevel(as.factor(age_cat), ref = \"40+\"),\n    `Marital status` = relevel(as.factor(`Marital status`), ref = \"Unmarried\"),\n    Residence = relevel(as.factor(Residence), ref = \"Urban\"),\n    Education = relevel(as.factor(Education), ref = \"Intermediate\"),\n    `Monthly income in PKR` = relevel(as.factor(`Monthly income in PKR`), ref = \">100,000\"))\n\nmultivariate_model <- glm(knowledge_dummy ~ Gender + Age + Residence + Education, \n                          data = analysis_data, family = binomial)\n\ntab_model(multivariate_model,\n          show.reflvl = TRUE,\n          show.intercept = FALSE,\n          dv.labels = \"\",\n          title = \"Model 1: Predictors of MPox knowledge (author age coded)\")\n\nmultivariate_model <- glm(knowledge_dummy ~ Gender + Age + Residence + Education, \n                          data = analysis_data, family = binomial)\n\ntab_model(multivariate_model,\n          show.reflvl = TRUE,\n          show.intercept = FALSE,\n          dv.labels = \"\",\n          title = \"Model 1: Predictors of MPox knowledge (author age coded)\")\nmultivariate_model2 <- glm(knowledge_dummy ~ Gender + age_cat + Residence + Education, \n                          data = analysis_data, family = binomial)\n\ntab_model(multivariate_model2,\n          show.reflvl = TRUE,\n          show.intercept = FALSE,\n          dv.labels = \"\",\n          title = \"Model 2: Predictors of MPox knowledge (corrected age coding)\")"},{"path":"week-8---logistic-regression.html","id":"test-yourself-1","chapter":"11 Week 8 - Logistic regression","heading":"11.5 Test yourself","text":"Run additional model see findings variables included analysis.","code":""},{"path":"week-9-assignment-data-details.html","id":"week-9-assignment-data-details","chapter":"12 Week 9 Assignment data details","heading":"12 Week 9 Assignment data details","text":"week, rest module now, working Scottish Health Survey 2021 data set chosen analysis modules final assessment.","code":""},{"path":"week-9-assignment-data-details.html","id":"read-in-the-data-and-codebook","chapter":"12 Week 9 Assignment data details","heading":"12.1 Read in the data and codebook","text":"now likely need explain read data R, seeing essential assignment probably best go best practices.likely coming back analysis script multiple times suggest creating folder three files. 1. R script (RMarkdown script, next week), 2. data file, 3. codebook. might also make good sense include pdfs related dataset, just know find .Open script file set working directory. can clicking Session -> Set Working Directory -> Choose Directory Source File Location. Alternatively, just avoid every time open script, can code setwd function. Also makes sense include packages use script top page.kind cut 2000 variables original dataset given far manageable 66 variables.Many variables still take data wrangling get usable format assignment analysis. help , include modifiable code chunks able use achieve .codebook document gives brief description variables (full account questions asked see associated questionnaire materials)., want full experience analysis dataset? Excellent!original file actually came SPSS format. , takes little playing get R. haven package useful . suggest saving file csv file continue analysis file.around 2000 variables hack way , perhaps able spot interesting variable missed. questions asked children good angle selection dataset cover.Good luck!","code":"\nsetwd(\"your_directory_path_here\")\nlibrary(\"packagename1\")\nlibrary(\"packagename2\")\nlibrary(\"packagename3\")\nlibrary(\"packagename~\")\n\nraw_data <- read_csv(\"Suggested SHES21 Dataset.csv\")\ncodebook <- read_csv(\"Codebook.csv\")"},{"path":"week-9-assignment-data-details.html","id":"video-walkthroughs","chapter":"12 Week 9 Assignment data details","heading":"12.2 Video walkthroughs","text":"","code":""},{"path":"week-9-assignment-data-details.html","id":"multiple-regression","chapter":"12 Week 9 Assignment data details","heading":"12.2.1 Multiple regression","text":"video setting data (need matter analysis conduct) conducting multiple regression.","code":""},{"path":"week-9-assignment-data-details.html","id":"logistic-regression","chapter":"12 Week 9 Assignment data details","heading":"12.2.2 Logistic regression","text":"video conduct logistic regression.","code":""},{"path":"week-9-assignment-data-details.html","id":"samples-code-for-you-to-adapt","chapter":"12 Week 9 Assignment data details","heading":"12.3 Samples code for you to adapt:","text":"","code":""},{"path":"week-9-assignment-data-details.html","id":"dealing-with-missing-data","chapter":"12 Week 9 Assignment data details","heading":"12.3.1 Dealing with missing data","text":"code adequate labeling missing data real NA's.","code":"\nmissing_values <- c(\"Unclassifiable\", \"Refused\", \"Don't know\", \n                    \"Schedule not obtained\", \"Schedule not applicable\", \"Not applicable\", \"Reading not obtained\")\n\ndata_cleaned <- data %>%\n  mutate_all(~replace(., . %in% missing_values, NA))"},{"path":"week-9-assignment-data-details.html","id":"checking-missing-data","chapter":"12 Week 9 Assignment data details","heading":"12.3.2 Checking missing data","text":"naniar package useful checking missing data large data sets. Install package run following code get plots summarise missing data","code":"\nlibrary(naniar)\n\ngg_miss_var(cleaned_data)\n\nvis_miss(cleaned_data)"},{"path":"week-9-assignment-data-details.html","id":"summary-of-catagorical-variables","chapter":"12 Week 9 Assignment data details","heading":"12.3.3 Summary of catagorical variables","text":"code summarises single categorical variable","code":"\ndata_cleaned %>%\n  group_by(variable) %>%\n  summarise(n = n())"},{"path":"week-9-assignment-data-details.html","id":"summary-of-numerical-variables","chapter":"12 Week 9 Assignment data details","heading":"12.3.4 Summary of numerical variables","text":"","code":"\ndata_cleaned %>%\n  summarise(average_x = mean(variable))"},{"path":"week-9-assignment-data-details.html","id":"converting-variable-from-character-to-numerical","chapter":"12 Week 9 Assignment data details","heading":"12.3.5 Converting variable from character to numerical","text":"Due missing data initially coded words (e.g. \"Unclassifiable\", \"Refused\", etc) date imported character variable, even data variable actually numbers. Run code replacing missing data get numerical variables ready analysis.","code":"\ndata_cleaned <- data %>%\n  mutate(variable = as.numeric(variable))"},{"path":"week-9-assignment-data-details.html","id":"recode-a-catagorical-variable-into-different-groupings","chapter":"12 Week 9 Assignment data details","heading":"12.3.6 Recode a catagorical variable into different groupings","text":"code takes variable computes new variable based specification. Useful want dichotomous catagorical variable two options.","code":"\ndata_cleaned <- data %>%\n  mutate(recoded_var = case_when(\n      original_var %in% c(\"A\", \"B\", \"C\") ~ \"Category1\",\n      original_var %in% c(\"D\", \"E\", \"F\") ~ \"Category2\",\n      TRUE ~ \"Other\"))"},{"path":"week-9-assignment-data-details.html","id":"reverse-code-a-numerical-likert-scale","chapter":"12 Week 9 Assignment data details","heading":"12.3.7 Reverse code a numerical likert scale","text":"easy way reverse code variable take original value away one top scale.example five point Likert scale. calculation 6 - [value]. 7 point Likert scale 8 - [value]","code":"\ndata_cleaned <- data %>%\n  mutate(var_5_point_reversed = 6 - var_5_point,\n         var_7_point_reversed = 8 - var_7_point,\n         var_10_point_reversed = 11 - var_10_point)"},{"path":"week-9-assignment-data-details.html","id":"coding-a-psychometric-scale-into-a-single-variable","chapter":"12 Week 9 Assignment data details","heading":"12.3.8 Coding a psychometric scale into a single variable","text":"first expression use numerical data. second expression takes likert scale expressed words converts numbers.","code":"\nrecoded_data <- recoded_data %>%\n  mutate(scale_score = mean(c_across(c(\"item1\", \"item2\")), na.rm = TRUE))\n\n#note you may need to convert the variable to numerical first\n\nrecoded_data <- data %>%\n  mutate(variable1 = recode(variable1,\n                           \"Not at all\" = 0,\n                           \"No more than usual\" = 1,\n                           \"Rather more than usual\" = 2,\n                           \"Much more than usual\" = 3))%>%\n  mutate(variable2 = recode(variable2,\n                           \"Not at all\" = 0,\n                           \"No more than usual\" = 1,\n                           \"Rather more than usual\" = 2,\n                           \"Much more than usual\" = 3))"},{"path":"week-9-assignment-data-details.html","id":"suggested-workflow","chapter":"12 Week 9 Assignment data details","heading":"12.4 Suggested workflow","text":"suggest cleaning wrangling script ends writing final data object csv file following code:start fresh R script RMarkdown file analysis.","code":"\nwrite_csv(data, \"name for your new csv file.csv\") #the .csv is important to  include."}]
